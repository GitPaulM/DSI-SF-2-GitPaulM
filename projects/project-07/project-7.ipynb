{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 7\n",
    "\n",
    "## NLP and Machine Learning on [travel.statsexchange.com](http://travel.stackexchange.com/) data\n",
    "\n",
    "---\n",
    "\n",
    "In Project 7 you'll be doing NLP and machine learning on post data from stackexchange's travel subdomain. \n",
    "\n",
    "This project is setup like a mini Kaggle competition. You are given the training data and when projects are submitted your model will be tested on the held-out testing data. There will be prizes for the people who build models that perform best on the held out test set!\n",
    "\n",
    "---\n",
    "\n",
    "## Notes on the data\n",
    "\n",
    "The data is again compressed into the `.7z` file format to save space. There are 6 .csv files and one readme file that contains some information on the fields.\n",
    "\n",
    "    posts_train.csv\n",
    "    comments_train.csv\n",
    "    users.csv\n",
    "    badges.csv\n",
    "    votes_train.csv\n",
    "    tags.csv\n",
    "    readme.txt\n",
    "    \n",
    "The data is located in your datasets folder:\n",
    "\n",
    "    DSI-SF-2/datasets/stack_exchange_travel.7z\n",
    "    \n",
    "If you're interested in where this data came from and where to get more data from other stackexchange subdomains, see here:\n",
    "\n",
    "https://ia800500.us.archive.org/22/items/stackexchange/readme.txt\n",
    "\n",
    "\n",
    "### Recommended Utilities for .7z\n",
    "\n",
    "- For OSX [Keka](http://www.kekaosx.com/en/) or [The Unarchiver](http://wakaba.c3.cx/s/apps/unarchiver.html). \n",
    "- For Windows [7-zip](http://www.7-zip.org/) is the standard. \n",
    "- For Linux try the `p7zip` utility.  `sudo apt-get install p7zip`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 1. Use LDA to find what topics are discussed on travel.stackexchange.com.\n",
    "\n",
    "---\n",
    "\n",
    "Text can be found in the posts and the comments datasets. The `ParentId` column in the posts dataset indicates what the \"question\" post was for a given post. Comment text can be merged onto the post they are part of with the `PostId` field.\n",
    "\n",
    "The text may have some HTML tags. BeautifulSoup has convenient ways to get rid of markup or extract text if you need to. You can also parse the strings yourself if you like.\n",
    "\n",
    "The tags dataset has the \"tags\" that the users have officially given the post.\n",
    "\n",
    "**1.1 Implement LDA against the text features of the dataset(s).**\n",
    "\n",
    "- This can be posts or a combination of posts and comments if you want more power.\n",
    "- Find optimal **K/num_topics**.\n",
    "\n",
    "**1.2 Compare your topics to the tags. Do the LDA topics make sense? How do they compare to the tags?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, matutils\n",
    "from sklearn import grid_search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41289 entries, 0 to 41288\n",
      "Data columns (total 21 columns):\n",
      "AcceptedAnswerId         6516 non-null float64\n",
      "AnswerCount              13988 non-null float64\n",
      "Body                     40476 non-null object\n",
      "ClosedDate               2627 non-null object\n",
      "CommentCount             41289 non-null int64\n",
      "CommunityOwnedDate       181 non-null object\n",
      "CreationDate             41289 non-null object\n",
      "FavoriteCount            3522 non-null float64\n",
      "Id                       41289 non-null int64\n",
      "LastActivityDate         41289 non-null object\n",
      "LastEditDate             23363 non-null object\n",
      "LastEditorDisplayName    844 non-null object\n",
      "LastEditorUserId         22883 non-null float64\n",
      "OwnerDisplayName         1173 non-null object\n",
      "OwnerUserId              40552 non-null float64\n",
      "ParentId                 23967 non-null float64\n",
      "PostTypeId               41289 non-null int64\n",
      "Score                    41289 non-null int64\n",
      "Tags                     13988 non-null object\n",
      "Title                    13988 non-null object\n",
      "ViewCount                13988 non-null float64\n",
      "dtypes: float64(7), int64(4), object(10)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#data fetch\n",
    "path = '/Users/paulmartin/Desktop/DSI-SF-2-GitPaulM/datasets/stack_exchange_travel/'\n",
    "\n",
    "tposts    = pd.read_csv(path+'posts_train.csv')\n",
    "tcomments = pd.read_csv(path+'comments_train.csv')\n",
    "users     = pd.read_csv(path+'users.csv')\n",
    "badges    = pd.read_csv(path+'badges.csv')\n",
    "tvotes    = pd.read_csv(path+'votes_train.csv')\n",
    "tags      = pd.read_csv(path+'tags.csv')\n",
    "tposts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean up some of the comments\n",
    "\n",
    "def chicken_noodle(x):\n",
    "    try:\n",
    "        y = BeautifulSoup(x, 'html.parser').get_text()\n",
    "        y = y.replace('\\n','')\n",
    "        y = y.replace('ewr','')\n",
    "        y.decode('quoted-printable').decode('utf-8')\n",
    "    except:\n",
    "        y = np.nan\n",
    "    return y\n",
    "\n",
    "tposts['Body2']= tposts['Body'].map(lambda x: chicken_noodle(x))\n",
    "tposts['Body2'].dropna(inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Vectorizer\n",
    "documents = tposts['Body2'].tolist()\n",
    "CountVectorizer()\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "vocab = {v: k for k, v in vectorizer.vocabulary_.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.015*flight + 0.012*airport + 0.009*ticket + 0.008*time + 0.006*check'),\n",
       " (1, u'0.007*like + 0.006*just + 0.006*people + 0.005*don + 0.005*use'),\n",
       " (2, u'0.033*visa + 0.014*passport + 0.010*uk + 0.010*need + 0.009*country')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LDA\n",
    "lda = models.LdaModel(\n",
    "    matutils.Sparse2Corpus(X, documents_columns=False),\n",
    "    num_topics  =  3,\n",
    "    passes      =  5,\n",
    "    id2word     =  vocab\n",
    ")\n",
    "\n",
    "lda.print_topics(num_topics=3, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Y = CountVectorizer()\n",
    "# Y.fit(temp)\n",
    "# columns=Y.get_feature_names()\n",
    "# columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleanup\n",
    "\n",
    "def cleantags(x):\n",
    "    try:\n",
    "        y = x.replace('<','')\n",
    "        y = y.replace('>',',')\n",
    "        y = y.replace('http','')\n",
    "        y = y.replace('com','')\n",
    "        y = y.replace('href','')\n",
    "        y = y.replace('amp','')\n",
    "        y = y.replace('www','')\n",
    "        y = y.replace('use','')\n",
    "        y = y.replace('li','')\n",
    "    except:\n",
    "        y = \"\"\n",
    "    return y\n",
    "\n",
    "tposts['Tags2']= tposts['Body'].map(lambda x: cleantags(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Vectorizer\n",
    "documents = tposts['Tags2'].tolist()\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "vocab = {v: k for k, v in vectorizer.vocabulary_.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.014*nofollow + 0.014*rel + 0.008*imgur + 0.008*stack + 0.008*train + 0.007*strong + 0.007*airport + 0.006*bus + 0.006*time + 0.005*jpg'),\n",
       " (1,\n",
       "  u'0.020*visa + 0.008*travel + 0.008*uk + 0.008*passport + 0.007*need + 0.007*strong + 0.007*fght + 0.007*em + 0.006*blockquote + 0.006*country'),\n",
       " (2,\n",
       "  u'0.009*strong + 0.008*em + 0.007*org + 0.007*rel + 0.006*people + 0.006*wikipedia + 0.006*nofollow + 0.006*wiki + 0.005*ke + 0.005*en')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LDA\n",
    "lda = models.LdaModel(\n",
    "    matutils.Sparse2Corpus(X, documents_columns=False),\n",
    "    num_topics  =  3,\n",
    "    passes      =  5,\n",
    "    id2word     =  vocab\n",
    ")\n",
    "\n",
    "lda.print_topics(num_topics=3, num_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 2. What makes an answer likely to be \"accepted\"?\n",
    "\n",
    "---\n",
    "\n",
    "**2.1 Build a model to predict whether a post will be marked as the answer.**\n",
    "\n",
    "- This is a classification problem.\n",
    "- You're free to use any of the machine learning algorithms or techniques we have learned in class to build the best model you can.\n",
    "- NLP will be very useful here for pulling out useful and relevant features from the data. \n",
    "- Though not required, using bagging and boosting models like Random Forests and Gradient Boosted Trees will _probably_ get you the highest performance on the test data (but who knows!).\n",
    "\n",
    "\n",
    "**2.2 Evaluate the performance of your classifier with a confusion matrix and accuracy. Explain how your model is performing.**\n",
    "\n",
    "**2.3 Plot either a ROC curve or precision-recall curve (or both!) and explain what they tell you about your model.**\n",
    "\n",
    "NOTE: You should only be predicting this for `PostTypeID=2` posts, which are the \"answer\" posts. This doesn't mean, however, that you can't or shouldn't use the parent questions as predictors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Flag_it(x):\n",
    "    y = 0\n",
    "    try:\n",
    "        if ((\"visa\" in x) or\n",
    "            (\"train\" in x) or\n",
    "            (\"passport\" in x) or\n",
    "            (\"airport\" in x) or\n",
    "            (\"travel\" in x) or\n",
    "            (\"country\" in x)):\n",
    "            y =1\n",
    "    except:\n",
    "        pass\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41289 entries, 0 to 41288\n",
      "Data columns (total 27 columns):\n",
      "AcceptedAnswerId         6516 non-null float64\n",
      "AnswerCount              13988 non-null float64\n",
      "Body                     40476 non-null object\n",
      "ClosedDate               2627 non-null object\n",
      "CommentCount             41289 non-null int64\n",
      "CommunityOwnedDate       181 non-null object\n",
      "CreationDate             41289 non-null object\n",
      "FavoriteCount            41289 non-null float64\n",
      "Id                       41289 non-null int64\n",
      "LastActivityDate         41289 non-null object\n",
      "LastEditDate             23363 non-null object\n",
      "LastEditorDisplayName    844 non-null object\n",
      "LastEditorUserId         22883 non-null float64\n",
      "OwnerDisplayName         1173 non-null object\n",
      "OwnerUserId              40552 non-null float64\n",
      "ParentId                 23967 non-null float64\n",
      "PostTypeId               41289 non-null int64\n",
      "Score                    41289 non-null int64\n",
      "Tags                     13988 non-null object\n",
      "Title                    13988 non-null object\n",
      "ViewCount                41289 non-null float64\n",
      "Body2                    35435 non-null object\n",
      "Tags2                    41289 non-null object\n",
      "Target                   41289 non-null int64\n",
      "NLPf                     41289 non-null int64\n",
      "Tagf                     41289 non-null int64\n",
      "CreationYear             41289 non-null int64\n",
      "dtypes: float64(7), int64(8), object(12)\n",
      "memory usage: 8.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Target</th>\n",
       "      <th>NLPf</th>\n",
       "      <th>Tagf</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>CreationYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>361.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9219.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>449.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>329.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>493.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>501.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>184.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>391.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>377.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41259</th>\n",
       "      <td>41259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>585.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41260</th>\n",
       "      <td>41260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41261</th>\n",
       "      <td>41261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41262</th>\n",
       "      <td>41262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41263</th>\n",
       "      <td>41263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41264</th>\n",
       "      <td>41264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41265</th>\n",
       "      <td>41265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41266</th>\n",
       "      <td>41266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41267</th>\n",
       "      <td>41267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41268</th>\n",
       "      <td>41268</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41269</th>\n",
       "      <td>41269</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41270</th>\n",
       "      <td>41270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41271</th>\n",
       "      <td>41271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41272</th>\n",
       "      <td>41272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41273</th>\n",
       "      <td>41273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41274</th>\n",
       "      <td>41274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41275</th>\n",
       "      <td>41275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41276</th>\n",
       "      <td>41276</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41277</th>\n",
       "      <td>41277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41278</th>\n",
       "      <td>41278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41279</th>\n",
       "      <td>41279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41280</th>\n",
       "      <td>41280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41281</th>\n",
       "      <td>41281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41282</th>\n",
       "      <td>41282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41283</th>\n",
       "      <td>41283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41284</th>\n",
       "      <td>41284</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41285</th>\n",
       "      <td>41285</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41286</th>\n",
       "      <td>41286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41287</th>\n",
       "      <td>41287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41288</th>\n",
       "      <td>41288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41289 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Target  NLPf  Tagf  Score  ViewCount  CommentCount  \\\n",
       "0          0       0     1     0      8      361.0             4   \n",
       "1          1       0     0     0      8      219.0             1   \n",
       "2          2       0     0     0     11      340.0             0   \n",
       "3          3       0     1     1     11     9219.0             2   \n",
       "4          4       0     0     0     12     1503.0             1   \n",
       "5          5       0     1     1     24     1604.0             1   \n",
       "6          6       0     1     0     11      449.0             4   \n",
       "7          7       0     1     1      7      329.0             4   \n",
       "8          8       0     1     1     57     4561.0             2   \n",
       "9          9       1     0     0     10        0.0             3   \n",
       "10        10       1     1     0     51        0.0             3   \n",
       "11        11       1     0     0     10        0.0             1   \n",
       "12        12       0     0     0     41     2448.0             3   \n",
       "13        13       0     1     1     34     2362.0             3   \n",
       "14        14       0     1     0     24      493.0             0   \n",
       "15        15       0     1     0      1     1268.0             3   \n",
       "16        16       1     1     0     10        0.0             4   \n",
       "17        17       0     0     1      8      501.0             0   \n",
       "18        18       1     1     0     26        0.0             5   \n",
       "19        19       0     0     1     11      184.0             7   \n",
       "20        20       0     0     0     13      391.0             5   \n",
       "21        21       1     1     0     13        0.0             3   \n",
       "22        22       1     0     0      6        0.0             0   \n",
       "23        23       1     1     0      5        0.0             0   \n",
       "24        24       1     1     0      8        0.0             2   \n",
       "25        25       1     1     0      6        0.0             1   \n",
       "26        26       1     1     0      7        0.0             2   \n",
       "27        27       1     1     0      5        0.0             0   \n",
       "28        28       0     0     0     21      377.0             2   \n",
       "29        29       1     0     0     22        0.0             0   \n",
       "...      ...     ...   ...   ...    ...        ...           ...   \n",
       "41259  41259       0     0     1      6      585.0             2   \n",
       "41260  41260       1     1     0      1        0.0             4   \n",
       "41261  41261       1     1     0      2        0.0             5   \n",
       "41262  41262       1     0     0      8        0.0             0   \n",
       "41263  41263       1     0     0     18        0.0             3   \n",
       "41264  41264       0     1     0      0       24.0             0   \n",
       "41265  41265       1     1     0      2        0.0             3   \n",
       "41266  41266       0     1     1      0       40.0             4   \n",
       "41267  41267       0     1     0      1       29.0             0   \n",
       "41268  41268       1     1     0     -1        0.0             3   \n",
       "41269  41269       1     1     0      0        0.0             0   \n",
       "41270  41270       1     1     0      1        0.0             0   \n",
       "41271  41271       1     0     0      0        0.0             0   \n",
       "41272  41272       1     0     0      0        0.0             1   \n",
       "41273  41273       1     1     0      1        0.0             0   \n",
       "41274  41274       0     0     0      0        0.0             0   \n",
       "41275  41275       0     0     0      0        0.0             0   \n",
       "41276  41276       0     1     0      0       32.0             6   \n",
       "41277  41277       1     1     0      1        0.0             0   \n",
       "41278  41278       1     1     0      0        0.0             0   \n",
       "41279  41279       1     1     0      2        0.0             0   \n",
       "41280  41280       1     1     0      1        0.0             0   \n",
       "41281  41281       0     0     1      0       28.0             0   \n",
       "41282  41282       1     1     0      3        0.0             0   \n",
       "41283  41283       1     1     0      2        0.0             0   \n",
       "41284  41284       1     0     0      0        0.0             0   \n",
       "41285  41285       1     0     0      0        0.0             0   \n",
       "41286  41286       1     1     0      2        0.0             0   \n",
       "41287  41287       0     0     0      1        3.0             0   \n",
       "41288  41288       1     1     0      1        0.0             3   \n",
       "\n",
       "       FavoriteCount  CreationYear  \n",
       "0                0.0          2011  \n",
       "1                0.0          2011  \n",
       "2                2.0          2011  \n",
       "3                1.0          2011  \n",
       "4                8.0          2011  \n",
       "5                4.0          2011  \n",
       "6                0.0          2011  \n",
       "7                0.0          2011  \n",
       "8               33.0          2011  \n",
       "9                0.0          2011  \n",
       "10               0.0          2011  \n",
       "11               0.0          2011  \n",
       "12              16.0          2011  \n",
       "13              12.0          2011  \n",
       "14               9.0          2011  \n",
       "15               0.0          2011  \n",
       "16               0.0          2011  \n",
       "17               0.0          2011  \n",
       "18               0.0          2011  \n",
       "19               0.0          2011  \n",
       "20               2.0          2011  \n",
       "21               0.0          2011  \n",
       "22               0.0          2011  \n",
       "23               0.0          2011  \n",
       "24               0.0          2011  \n",
       "25               0.0          2011  \n",
       "26               0.0          2011  \n",
       "27               0.0          2011  \n",
       "28               1.0          2011  \n",
       "29               0.0          2011  \n",
       "...              ...           ...  \n",
       "41259            0.0          2016  \n",
       "41260            0.0          2016  \n",
       "41261            0.0          2016  \n",
       "41262            0.0          2016  \n",
       "41263            0.0          2016  \n",
       "41264            0.0          2016  \n",
       "41265            0.0          2016  \n",
       "41266            0.0          2016  \n",
       "41267            0.0          2016  \n",
       "41268            0.0          2016  \n",
       "41269            0.0          2016  \n",
       "41270            0.0          2016  \n",
       "41271            0.0          2016  \n",
       "41272            0.0          2016  \n",
       "41273            0.0          2016  \n",
       "41274            0.0          2016  \n",
       "41275            0.0          2016  \n",
       "41276            0.0          2016  \n",
       "41277            0.0          2016  \n",
       "41278            0.0          2016  \n",
       "41279            0.0          2016  \n",
       "41280            0.0          2016  \n",
       "41281            0.0          2016  \n",
       "41282            0.0          2016  \n",
       "41283            0.0          2016  \n",
       "41284            0.0          2016  \n",
       "41285            0.0          2016  \n",
       "41286            0.0          2016  \n",
       "41287            1.0          2016  \n",
       "41288            0.0          2016  \n",
       "\n",
       "[41289 rows x 9 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prep\n",
    "Xforpipe = tposts\n",
    "tposts.info()\n",
    "\n",
    "tposts['Target'] = tposts['PostTypeId'].map(lambda x: 1 if x == 2 else 0)\n",
    "tposts['NLPf'] = tposts['Body'].map(lambda x: Flag_it(x))\n",
    "tposts['Tagf'] = tposts['Tags'].map(lambda x: Flag_it(x))\n",
    "tposts['CreationYear'] = tposts['CreationDate'].map(lambda x: int(x[:4]))\n",
    "tposts['ViewCount'] .fillna(0, inplace=True)\n",
    "tposts['FavoriteCount'] .fillna(0, inplace=True)\n",
    "\n",
    "df_cols = ['Target','NLPf','Tagf','Score','ViewCount','CommentCount','FavoriteCount','CreationYear']\n",
    "df = tposts[df_cols]\n",
    "df.iloc[np.random.permutation(len(df))]\n",
    "df.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conf_class(mod, X, y, margins=False):\n",
    "    pred = pd.Series(mod.predict(X), name='Predicted')\n",
    "    true = pd.Series(y, name='True')\n",
    "    confusion = pd.crosstab(true, pred, margins=margins)\n",
    "    print \"Confusion Matrix:\"\n",
    "    print confusion\n",
    "    print \"\\nClassification Report:\"\n",
    "    classify_rept = classification_report(y, pred)\n",
    "    print classify_rept\n",
    "    return confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41289, 8)\n",
      "(41289, 7) (41289,)\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: 1\n",
      "Best Params: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}\n",
      "Best Score: 0.948694142817\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "print df.shape\n",
    "X = df.iloc[:,1:]\n",
    "y = np.ravel([df['Target']])\n",
    "Xpipe = X # for prob 5\n",
    "ypipe = y # for prob 5\n",
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)\n",
    "\n",
    "print Xn.shape, y.shape\n",
    "X_train, X_test, y_train, y_test =  train_test_split(Xn, y, test_size=0.4)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "search_parameters = {\n",
    "    'n_neighbors':  range(1,10,2), \n",
    "    'weights':      (\"uniform\", \"distance\"),\n",
    "    'algorithm':    (\"ball_tree\", \"kd_tree\", \"brute\", \"auto\"),\n",
    "    'p':            [1,2]\n",
    "}\n",
    "\n",
    "\n",
    "knns = grid_search.GridSearchCV(knn, search_parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "knns.fit(X_train, y_train)\n",
    "print \"Best Estimator:\", knns.best_estimator_.n_neighbors\n",
    "print \"Best Params:\", knns.best_params_\n",
    "print \"Best Score:\", knns.best_score_\n",
    "y_pred = knns.predict(X_test)\n",
    "y_knn = ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "Predicted     0     1\n",
      "True                 \n",
      "0          6479   465\n",
      "1           287  9285\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.93      0.95      6944\n",
      "          1       0.95      0.97      0.96      9572\n",
      "\n",
      "avg / total       0.95      0.95      0.95     16516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc = conf_class(knns, X_test, y_test, margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:   35.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
      "           max_features=4, max_leaf_nodes=7, min_samples_leaf=1,\n",
      "           min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "==========\n",
      "\n",
      "best parameters {'max_features': 4, 'max_leaf_nodes': 7, 'min_samples_split': 4, 'n_estimators': 50, 'max_depth': 5}\n",
      "\n",
      "==========\n",
      "\n",
      "best score 0.95433806533\n"
     ]
    }
   ],
   "source": [
    "#Random Forest for comparison\n",
    "\n",
    "forest = RandomForestRegressor( )\n",
    "\n",
    "params = {'max_depth':[3,4,5], \n",
    "          'max_features':[2,3,4], \n",
    "          'max_leaf_nodes':[5,6,7], \n",
    "          'min_samples_split':[3,4],\n",
    "          'n_estimators': [50]\n",
    "         }\n",
    "\n",
    "rf_gs = GridSearchCV(forest, params, n_jobs=-1,  cv=5,verbose=1) \n",
    "\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "## Print best estimator, best parameters, and best score\n",
    "rf_gs_best = rf_gs.best_estimator_\n",
    "print \"best estimator\", rf_gs_best\n",
    "print \"\\n==========\\n\"\n",
    "print \"best parameters\", rf_gs.best_params_\n",
    "print \"\\n==========\\n\"\n",
    "print \"best score\", rf_gs.best_score_\n",
    "y_hat = rf_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#confusion matrix did not work for Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsClassifier' object has no attribute 'decision_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-0d3c558d0fb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# [insert explanation of this section -- what is this for?  Where do we use this later?]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# not needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mY_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Confulson matrix metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'decision_function'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "# [insert explanation of this section -- what is this for?  Where do we use this later?]\n",
    "# not needed\n",
    "Y_score = knn.decision_function(X_train)\n",
    "\n",
    "# Confulson matrix metrics\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "\n",
    "# an assigning ofsets from the 2nd set of probabilities from my .predict_proba() predictions\n",
    "#this data is what will be plotted once we throw it to the figure\n",
    "FPR[1], TPR[1], _ = roc_curve(y, probabilities[:, 1])\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "# initialize a plank plot al?]\n",
    "plt.figure(figsize=[11,9])\n",
    "#plot my false and true rates (returned from a ROC curve)\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "\n",
    "#plot a dotted line diagonally, representing .5 (can we do better than guessing)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic for \"over_200k\" predictions', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 3. What is the score of a post?\n",
    "\n",
    "---\n",
    "\n",
    "**3.1 Build a model that predicts the score of a post.**\n",
    "\n",
    "- This is a regression problem now. \n",
    "- You can and should be predicting score for both \"question\" and \"answer\" posts, so keep them both in your dataset.\n",
    "- Again, use any techniques that you think will get you the best model.\n",
    "\n",
    "**3.2 Evaluate the performance of your model with cross-validation and report the results.**\n",
    "\n",
    "**3.3 What is important for determining the score of a post, if anything?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41289, 8)\n",
      "['PostTypeId', 'NLPf', 'Tagf', 'Score', 'ViewCount', 'CommentCount', 'FavoriteCount', 'CreationYear']\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_cols = ['PostTypeId','NLPf','Tagf','Score','ViewCount','CommentCount','FavoriteCount','CreationYear']\n",
    "df = tposts[df_cols]\n",
    "print df.shape\n",
    "print df_cols\n",
    "print type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41289, 7) (41289,)\n"
     ]
    }
   ],
   "source": [
    "y = np.ravel([df['Score']])\n",
    "X = df[[x for x in df_cols if x not in ['PostTypeID','Score']]]\n",
    "feature_cols = X.columns.values\n",
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)\n",
    "\n",
    "print Xn.shape, y.shape\n",
    "X_train, X_test, y_train, y_test =  train_test_split(Xn, y, test_size=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/dsi/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24777911  0.24181269  0.19139394  0.18743163  0.14463263] 0.202609999622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier(n_estimators=2)\n",
    "adb.fit(X, y)\n",
    "adb_scores = cross_val_score(adb, X, y, cv=5)\n",
    "print adb_scores, np.mean(adb_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model not great. Note Gradient Boost did not yield results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PostTypeId</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CommentCount</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLPf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tagf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ViewCount</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FavoriteCount</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CreationYear</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "0     PostTypeId         0.5\n",
       "4   CommentCount         0.5\n",
       "1           NLPf         0.0\n",
       "2           Tagf         0.0\n",
       "3      ViewCount         0.0\n",
       "5  FavoriteCount         0.0\n",
       "6   CreationYear         0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print Feature importances\n",
    "feature_importance = pd.DataFrame({ 'feature':feature_cols, \n",
    "                                   'importance':adb.feature_importances_\n",
    "                                  })\n",
    "\n",
    "feature_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 4. How many views does a post have?\n",
    "\n",
    "---\n",
    "\n",
    "**4.1 Build a model that predicts the number of views a post has.**\n",
    "\n",
    "- This is another regression problem. \n",
    "- Predict the views for all posts, not just the \"answer\" posts.\n",
    "\n",
    "**4.2 Evaluate the performance of your model with cross-validation and report the results.**\n",
    "\n",
    "**4.3 What is important for the number of views a post has, if anything?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41289, 8)\n",
      "['PostTypeId', 'NLPf', 'Tagf', 'Score', 'ViewCount', 'CommentCount', 'FavoriteCount', 'CreationYear']\n"
     ]
    }
   ],
   "source": [
    "df_cols = ['PostTypeId','NLPf','Tagf','Score','ViewCount','CommentCount','FavoriteCount','CreationYear']\n",
    "df = tposts[df_cols]\n",
    "print df.shape\n",
    "print df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41289, 6) (41289,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([u'NLPf', u'Tagf', u'Score', u'CommentCount', u'FavoriteCount',\n",
       "       u'CreationYear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ravel([df['ViewCount']])\n",
    "X = df[[x for x in df_cols if x not in ['ViewCount','PostTypeId']]]\n",
    "feature_cols = X.columns\n",
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)\n",
    "\n",
    "print Xn.shape, y.shape\n",
    "X_train, X_test, y_train, y_test =  train_test_split(Xn, y, test_size=0.4)\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.50946852  0.1697011  -0.06927937  0.09396441 -2.55529346] -1.57407516782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(max_depth=10)\n",
    "rfr.fit(Xn, y)\n",
    "rfr_scores = cross_val_score(rfr, Xn, y, cv=5)\n",
    "print rfr_scores, np.mean(rfr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Score</td>\n",
       "      <td>0.296347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FavoriteCount</td>\n",
       "      <td>0.295878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CommentCount</td>\n",
       "      <td>0.171134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CreationYear</td>\n",
       "      <td>0.150149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLPf</td>\n",
       "      <td>0.046042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tagf</td>\n",
       "      <td>0.040451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "2          Score    0.296347\n",
       "4  FavoriteCount    0.295878\n",
       "3   CommentCount    0.171134\n",
       "5   CreationYear    0.150149\n",
       "0           NLPf    0.046042\n",
       "1           Tagf    0.040451"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print Feature importances\n",
    "feature_importance = pd.DataFrame({ 'feature':feature_cols, \n",
    "                                   'importance':rfr.feature_importances_\n",
    "                                  })\n",
    "\n",
    "feature_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 5. Build a pipeline or other code to automate evaluation of your models on the test data.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you've constructed your three predictive models, build a pipeline or code that can easily load up the raw testing data and evaluate your models on it.\n",
    "\n",
    "The testing data that is held out is in the same raw format as the training data you have. _Any cleaning and preprocessing that you did on the training data will need to be done on the testing data as well!_\n",
    "\n",
    "This is a good opportunity to practice building pipelines, but you're not required to. Custom functions and classes are fine as long as they are able to process and test the new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# df_cols = ['Target','NLPf','Tagf','Score','ViewCount','CommentCount','FavoriteCount','CreationYear']\n",
    "# df = tposts[df_cols]\n",
    "# df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PipelinePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _create_features(self, df): \n",
    "        df['NLPf'] = df['Body'].map(lambda x: Flag_it(x))\n",
    "        df['Tagf'] = df['Tags'].map(lambda x: Flag_it(x))\n",
    "        df['Target'] = df['PostTypeId'].map(lambda x: 1 if x == 2 else 0)\n",
    "        return df\n",
    "    \n",
    "    def _get_year(self, df):\n",
    "        df['CreationYear'] = df['CreationDate'].map(lambda x: int(x[:4]))\n",
    "        return df\n",
    "    \n",
    "    def _manage_nulls(self,df):\n",
    "        df['ViewCount'] .fillna(0, inplace=True)\n",
    "        df['FavoriteCount'] .fillna(0, inplace=True)\n",
    "        return df\n",
    "    \n",
    "# Originally in but decided to exclude from the pipline.\n",
    "    \n",
    "#     def _build_df(self, df):\n",
    "#         df_cols = ['Target','NLPf','Tagf','Score','ViewCount','CommentCount','FavoriteCount','CreationYear']\n",
    "#         df = df[df_cols]\n",
    "#         df.iloc[np.random.permutation(len(df))]\n",
    "#         return df\n",
    "    \n",
    "    def transform(self, X, *args):\n",
    "        X = self._create_features(X)\n",
    "        X = self._get_year(X)\n",
    "        X = self._manage_nulls(X)\n",
    " #       X = self._build_df(X)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, *args):\n",
    "        return self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe_prep = PipelinePreprocessor()\n",
    "ss = StandardScaler()\n",
    "knn_for_pipe =  KNeighborsClassifier(n_neighbors=1,weights='uniform',algorithm='brute',p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "knn_pipe = Pipeline(steps=[('ss', ss),\n",
    "                          ('knnfp', knn_for_pipe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best Estimator: 1\n",
    "# Best Params: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}\n",
    "# Best Score: 0.953699592298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41289, 7), (41289,))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xpipe.shape, ypipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20644, 7) (20644,) (20645, 7) (20645,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9392104625817389"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test train the data and fit the model\n",
    "\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xpipe, ypipe, test_size=0.5)\n",
    "print Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "knn_pipe.fit(Xtrain, ytrain)\n",
    "knn_pipe.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
