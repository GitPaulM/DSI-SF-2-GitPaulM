{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 4\n",
    "\n",
    "## Help Yelp\n",
    "\n",
    "---\n",
    "\n",
    "In this project you will be investigating a small version of the [Yelp challenge dataset](https://www.yelp.com/dataset_challenge). You'll practice using classification algorithms, cross-validation, gridsearching â€“ all that good stuff.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The data\n",
    "\n",
    "There are 5 individual .csv files that have the information, zipped into .7z format like with the SF data last project. The dataset is located in your datasets folder:\n",
    "\n",
    "    DSI-SF-2/datasets/yelp_arizona_data.7z\n",
    "\n",
    "The columns in each are:\n",
    "\n",
    "    businesses_small_parsed.csv\n",
    "        business_id: unique business identifier\n",
    "        name: name of the business\n",
    "        review_count: number of reviews per business\n",
    "        city: city business resides in\n",
    "        stars: average rating\n",
    "        categories: categories the business falls into (can be one or multiple)\n",
    "        latitude\n",
    "        longitude\n",
    "        neighborhoods: neighborhoods business belongs to\n",
    "        variable: \"property\" of the business (a tag)\n",
    "        value: True/False for the property\n",
    "        \n",
    "    reviews_small_nlp_parsed.csv\n",
    "        user_id: unique user identifier\n",
    "        review_id: unique review identifier\n",
    "        votes.cool: how many thought the review was \"cool\"\n",
    "        business_id: unique business id the review is for\n",
    "        votes.funny: how many thought the review was funny\n",
    "        stars: rating given\n",
    "        date: date of review\n",
    "        votes.useful: how many thought the review was useful\n",
    "        ... 100 columns of counts of most common 2 word phrases that appear in reviews in this review\n",
    "        \n",
    "    users_small_parsed.csv\n",
    "        yelping_since: signup date\n",
    "        compliments.plain: # of compliments \"plain\"\n",
    "        review_count: # of reviews:\n",
    "        compliments.cute: total # of compliments \"cute\"\n",
    "        compliments.writer: # of compliments \"writer\"\n",
    "        compliments.note: # of compliments \"note\" (not sure what this is)\n",
    "        compliments.hot: # of compliments \"hot\" (?)\n",
    "        compliments.cool: # of compliments \"cool\"\n",
    "        compliments.profile: # of compliments \"profile\"\n",
    "        average_stars: average rating\n",
    "        compliments.more: # of compliments \"more\"\n",
    "        elite: years considered \"elite\"\n",
    "        name: user's name\n",
    "        user_id: unique user id\n",
    "        votes.cool: # of votes \"cool\"\n",
    "        compliments.list: # of compliments \"list\"\n",
    "        votes.funny: # of compliments \"funny\"\n",
    "        compliments.photos: # of compliments \"photos\"\n",
    "        compliments.funny: # of compliments \"funny\"\n",
    "        votes.useful: # of votes \"useful\"\n",
    "       \n",
    "    checkins_small_parsed.csv\n",
    "        business_id: unique business identifier\n",
    "        variable: day-time identifier of checkins (0-0 is Sunday 0:00 - 1:00am,  for example)\n",
    "        value: # of checkins at that time\n",
    "    \n",
    "    tips_small_nlp_parsed.csv\n",
    "        user_id: unique user identifier\n",
    "        business_id: unique business identifier\n",
    "        likes: likes that the tip has\n",
    "        date: date of tip\n",
    "        ... 100 columns of counts of most common 2 word phrases that appear in tips in this tip\n",
    "\n",
    "The reviews and tips datasets in particular have parsed \"NLP\" columns with counts of 2-word phrases in that review or tip (a \"tip\", it seems, is some kind of smaller review).\n",
    "\n",
    "The user dataset has a lot of columns of counts of different compliments and votes. I'm not sure whether the compliments or votes are _by_ the user or _for_ the user.\n",
    "\n",
    "---\n",
    "\n",
    "If you look at the website, or the full data, you'll see I have removed pieces of the data and cut it down quite a bit. This is to simplify it for this project. Specifically, business are limited to be in these cities:\n",
    "\n",
    "    Phoenix\n",
    "    Surprise\n",
    "    Las Vegas\n",
    "    Waterloo\n",
    "\n",
    "Apparently there is a city called \"Surprise\" in Arizona. \n",
    "\n",
    "Businesses are also restricted to at least be in one of the following categories, because I thought the mix of them was funny:\n",
    "\n",
    "    Airports\n",
    "    Breakfast & Brunch\n",
    "    Bubble Tea\n",
    "    Burgers\n",
    "    Bars\n",
    "    Bakeries\n",
    "    Breweries\n",
    "    Cafes\n",
    "    Candy Stores\n",
    "    Comedy Clubs\n",
    "    Courthouses\n",
    "    Dance Clubs\n",
    "    Fast Food\n",
    "    Museums\n",
    "    Tattoo\n",
    "    Vape Shops\n",
    "    Yoga\n",
    "    \n",
    "---\n",
    "\n",
    "### Project requirements\n",
    "\n",
    "**You will be performing 4 different sections of analysis, like in the last project.**\n",
    "\n",
    "Remember that classification targets are categorical and regression targets are continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Constructing a \"profile\" for Las Vegas\n",
    "\n",
    "---\n",
    "\n",
    "Yelp is interested in building out what they are calling \"profiles\" for cities. They want you to start with just Las Vegas to see what a prototype of this would look like. Essentially, they want to know what makes Las Vegas distinct from the other four.\n",
    "\n",
    "Use the data you have to predict Las Vegas from the other variables you have. You should not be predicting the city from any kind of location data or other data perfectly associated with that city (or another city).\n",
    "\n",
    "You may use any classification algorithm you deem appropriate, or even multiple models. You should:\n",
    "\n",
    "1. Build at least one model predicting Las Vegas vs. the other cities.\n",
    "- Validate your model(s).\n",
    "- Interpret and visualize, in some way, the results.\n",
    "- Write up a \"profile\" for Las Vegas. This should be a writeup converting your findings from the model(s) into a human-readable description of the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the business field\n",
    "pathb = '/Users/paulmartin/Desktop/DSI-SF-2-GitPaulM/datasets/yelp_arizona_data/businesses_small_parsedb.csv'\n",
    "biz = pd.read_csv(pathb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lv_flag ~ Review_count + Stars + Divey + Dietary_restrictions_vegan + Happy_hour + Order_at_counter + Byob + Good_for_latenight + Outdoor_seating + Classy + By_appointment_only + Parking_lot + Touristy + Corkage + Good_for_brunch + Waiter_service + Parking_street + Hipster + Music_live + Music_background_music + Good_for_breakfast + Parking_garage + Music_karaoke + Good_for_dancing + Accepts_credit_cards + Good_for_lunch + Parking_valet + Take_out + Good_for_dessert + Music_video + Takes_reservations + Trendy + Delivery + Open + Wheelchair_accessible + Dietary_restrictions_gluten_free + Caters + Intimate + Good_for_dinner + Coat_check + Good_for_kids + Parking_validated + Music_dj + Has_tv + Casual + Dogs_allowed + Drive_thru + Dietary_restrictions_vegetarian + Good_for_groups + Open_24_hours + Romantic + Music_jukebox + Upscale - 1'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Las Vegas Binary Field (either or)\n",
    "\n",
    "biz_lv = biz\n",
    "biz_lv['lv_flag'] = biz_lv['city'].map(lambda x: 1 if x == \"Las Vegas\" else 0)\n",
    "\n",
    "\n",
    "#clean column names  (Note to self:  stringing replaces does not seem  work as planned with multiple replacements))\n",
    "# probably a better way to do this in place, but this works\n",
    "\n",
    "new_col = [x.replace('attributes.','').replace('hours.','').replace('Ambience.','') for x in biz_lv.columns.values]\n",
    "new_col = [x.replace(' ','_').replace('-','_') for x in new_col]\n",
    "new_col = [x.replace('.','_').capitalize() for x in new_col]\n",
    "biz_lv.columns = new_col\n",
    "\n",
    "# Eliminate columns with zeroes\n",
    "\n",
    "biz_lv = biz_lv.loc[:, (biz_lv != 0).any(axis=0)] #http://stackoverflow.com/questions/21164910/delete-column-in-pandas-based-on-condition\n",
    "\n",
    "# Columns (since we are here): the patsy formula\n",
    "\n",
    "form_lv=[]\n",
    "[form_lv.append(x) for x in biz_lv.columns if x not in ['Business_id','City','Name','Lv_flag']]\n",
    "form =  ' + '.join(form_lv)\n",
    "formula_lv = 'Lv_flag ~ ' + form + ' - 1'\n",
    "formula_lv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### pathr = '/Users/paulmartin/Desktop/DSI-SF-2-GitPaulM/datasets/yelp_arizona_data/reviews_small_nlp_parsed.csv'\n",
    "reviews = pd.read_csv(pathr)\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle/stratify\n",
    "biz_lv = biz_lv.sample(frac=1).reset_index(drop=True)  #http://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "\n",
    "# slice \n",
    "biz_lv_small = biz_lv[0:35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#patsy: (Remember:  ravel the y, and use iloc with train/test)\n",
    "y,X = patsy.dmatrices(formula_lv, data=biz_lv_small, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> (35000,)\n",
      "<class 'pandas.core.frame.DataFrame'> (35000, 53)\n"
     ]
    }
   ],
   "source": [
    "# confirm\n",
    "y = np.ravel(y)\n",
    "print type(y), y.shape\n",
    "print type(X), X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.StratifiedKFold(labels=[ 1.  1.  1. ...,  0.  0.  0.], n_folds=5, shuffle=False, random_state=None)\n",
      "Logistic Regression:\n",
      "[0.61823117588226895]\n",
      "0.618231175882\n",
      "Baseline accuracy: 0.616942857143\n"
     ]
    }
   ],
   "source": [
    "#Set up the indices, get the model and cross validate   Use log reg as classification model.\n",
    "cv_indices = StratifiedKFold(y, n_folds=5)\n",
    "logreg = LogisticRegression()\n",
    "lr_scores = []\n",
    "\n",
    "# cross validate i.e. train / test\n",
    "for traini, testi in cv_indices:\n",
    "    Xtr, ytr  = X.iloc[traini, :], y[traini]\n",
    "    Xte, yte =  X.iloc[testi, :], y[testi]\n",
    "  \n",
    "logreg.fit(Xtr, ytr)\n",
    "lr_scores.append(logreg.score(Xte, yte))\n",
    "\n",
    "print cv_indices    \n",
    "\n",
    "print 'Logistic Regression:'\n",
    "print lr_scores\n",
    "print np.mean(lr_scores)\n",
    "\n",
    "print 'Baseline accuracy:', np.mean(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.01      0.03     13537\n",
      "        1.0       0.61      0.99      0.76     21463\n",
      "\n",
      "avg / total       0.60      0.61      0.48     35000\n",
      "\n",
      "Predicted  0.0    1.0    All\n",
      "Actual                      \n",
      "0.0        178  13359  13537\n",
      "1.0        135  21328  21463\n",
      "All        313  34687  35000\n"
     ]
    }
   ],
   "source": [
    "#Classification report / Confusion matrix\n",
    "\n",
    "y_pred = logreg.predict(X)\n",
    "print type(y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y, y_pred)\n",
    "print cls_rep\n",
    "\n",
    "confusion = pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize for regularization\n",
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:   15.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:  1.1min\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 183.67355102040815, 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Let's use Grid search and regularization to see if there is a difference in the model.  More academic really.\n",
    "\n",
    "lr_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.linspace(0.0001, 1000, 50)\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(LogisticRegression(), lr_params, cv=5, verbose=1)\n",
    "\n",
    "lr_gs.fit(Xn, y)\n",
    "print lr_gs.best_params_\n",
    "best_lr = lr_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.03      0.06     13537\n",
      "        1.0       0.62      0.99      0.76     21463\n",
      "\n",
      "avg / total       0.60      0.62      0.49     35000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the predictions for the confusion matrix, based on new data.  Largee data sets, not\n",
    "# expecting any surprises\n",
    "\n",
    "\n",
    "y_pred = lr_gs.predict(Xn)\n",
    "print type(y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y, y_pred)\n",
    "print cls_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "[0.61591201256963291, 0.61219825739180123, 0.61642857142857144, 0.61680240034290612, 0.61480211458779821]\n",
      "0.615228671264\n",
      "Baseline accuracy: 0.613228571429\n"
     ]
    }
   ],
   "source": [
    "# Cross validate the best model\n",
    "\n",
    "cv_indices = StratifiedKFold(y, n_folds=5)\n",
    "\n",
    "lr_scores = []\n",
    "\n",
    "for train_inds, test_inds in cv_indices:\n",
    "    \n",
    "    Xtr, ytr = Xn[train_inds, :], y[train_inds]\n",
    "    Xte, yte = Xn[test_inds, :], y[test_inds]\n",
    "   \n",
    "    best_lr.fit(Xtr, ytr)\n",
    "    lr_scores.append(best_lr.score(Xte, yte))\n",
    "    \n",
    "\n",
    "print 'Logistic Regression:'\n",
    "print lr_scores\n",
    "print np.mean(lr_scores)\n",
    "\n",
    "print 'Baseline accuracy:', np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000,)\n",
      "(35000, 53)\n"
     ]
    }
   ],
   "source": [
    "# So the mean scores are consistent  Unlikely suprising given the data set.  \n",
    "# Let's examine the confusion matrix\n",
    "print y.shape\n",
    "print Xn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.03      0.06     13537\n",
      "        1.0       0.62      0.99      0.76     21463\n",
      "\n",
      "avg / total       0.60      0.62      0.49     35000\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted  0.0    1.0    All\n",
      "Actual                      \n",
      "0.0        398  13139  13537\n",
      "1.0        310  21153  21463\n",
      "All        708  34292  35000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the predictions for the confusion matrix and the classification report , based on new data\n",
    "\n",
    "\n",
    "y_pred = best_lr.predict(Xn)\n",
    "print type(y_pred)\n",
    "\n",
    "print \"Classification Report\"\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y, y_pred)\n",
    "print cls_rep\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "confusion = pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    abs_coef      coef                          variable\n",
      "0   0.341452  0.341452                      Review_count\n",
      "13  0.124498  0.124498                           Corkage\n",
      "49  0.114595  0.114595                     Open_24_hours\n",
      "52  0.102254  0.102254                           Upscale\n",
      "21  0.087549  0.087549                    Parking_garage\n",
      "50  0.072007  0.072007                          Romantic\n",
      "8   0.071275 -0.071275                   Outdoor_seating\n",
      "47  0.059184 -0.059184   Dietary_restrictions_vegetarian\n",
      "35  0.058542 -0.058542  Dietary_restrictions_gluten_free\n",
      "26  0.052823  0.052823                     Parking_valet\n"
     ]
    }
   ],
   "source": [
    "ls = X.columns.values.tolist()\n",
    "coefs = pd.DataFrame({'variable':ls,'coef':best_lr.coef_[0], 'abs_coef':np.abs(best_lr.coef_[0])})\n",
    "coefs.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "print coefs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Review_count', 'Stars', 'Divey', 'Dietary_restrictions_vegan', 'Happy_hour', 'Order_at_counter', 'Byob', 'Good_for_latenight', 'Outdoor_seating', 'Classy', 'By_appointment_only', 'Parking_lot', 'Touristy', 'Corkage', 'Good_for_brunch', 'Waiter_service', 'Parking_street', 'Hipster', 'Music_live', 'Music_background_music', 'Good_for_breakfast', 'Parking_garage', 'Music_karaoke', 'Good_for_dancing', 'Accepts_credit_cards', 'Good_for_lunch', 'Parking_valet', 'Take_out', 'Good_for_dessert', 'Music_video', 'Takes_reservations', 'Trendy', 'Delivery', 'Open', 'Wheelchair_accessible', 'Dietary_restrictions_gluten_free', 'Caters', 'Intimate', 'Good_for_dinner', 'Coat_check', 'Good_for_kids', 'Parking_validated', 'Music_dj', 'Has_tv', 'Casual', 'Dogs_allowed', 'Drive_thru', 'Dietary_restrictions_vegetarian', 'Good_for_groups', 'Open_24_hours', 'Romantic', 'Music_jukebox', 'Upscale']\n"
     ]
    }
   ],
   "source": [
    "print ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-41983edc9255>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-41983edc9255>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    ax.set_xlabel(coefs.,fontsize=12)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "top_ten = coefs.columns.values.tolist()\n",
    "top_ten = top_ten\n",
    "ax = coefs.head(10)[['abs_coef']].plot(kind='bar', title =\"Top Coefficients\",figsize=(15,10),legend=True, fontsize=12)\n",
    "ax.set_xlabel(top_ten,fontsize=12)\n",
    "ax.set_ylabel(\"Absolute Coeff Value\",fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# ax = df[['V1','V2']].plot(kind='bar', title =\"V comp\",figsize=(15,10),legend=True, fontsize=12)\n",
    "# ax.set_xlabel(\"Hour\",fontsize=12)\n",
    "# ax.set_ylabel(\"V\",fontsize=12)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the top 10 variables: The Las Vegas profile is one of convenience, fun, and entertainment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Different categories of ratings\n",
    "\n",
    "---\n",
    "\n",
    "Yelp is finally ready to admit that their rating system sucks. No one cares about the ratings, they just use the site to find out what's nearby. The ratings are simply too unreliable for people. \n",
    "\n",
    "Yelp hypothesizes that this is, in fact, because different people tend to give their ratings based on different things. They believe that perhaps some people always base their ratings on quality of food, others on service, and perhaps other categories as well. \n",
    "\n",
    "1. Do some users tend to talk about service more than others in reviews/tips? Divide up the tips/reviews into more \"service-focused\" ones and those less concerned with service.\n",
    "2. Create two new ratings for businesses: ratings from just the service-focused reviews and ratings from the non-service reviews.\n",
    "3. Construct a regression model for each of the two ratings. They should use the same predictor variables (of your choice). \n",
    "4. Validate the performance of the models.\n",
    "5. Do the models coefficients differ at all? What does this tell you about the hypothesis that there are in fact two different kinds of ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322398, 108)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>votes.cool</th>\n",
       "      <th>business_id</th>\n",
       "      <th>votes.funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>votes.useful</th>\n",
       "      <th>10 minutes</th>\n",
       "      <th>15 minutes</th>\n",
       "      <th>...</th>\n",
       "      <th>service great</th>\n",
       "      <th>staff friendly</th>\n",
       "      <th>super friendly</th>\n",
       "      <th>sweet potato</th>\n",
       "      <th>tasted like</th>\n",
       "      <th>time vegas</th>\n",
       "      <th>try place</th>\n",
       "      <th>ve seen</th>\n",
       "      <th>ve tried</th>\n",
       "      <th>wait staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o_LCYay4uo5N4eq3U5pbrQ</td>\n",
       "      <td>biEOCicjWlibF26pNLvhcw</td>\n",
       "      <td>0</td>\n",
       "      <td>EmzaQR5hQlF0WIl24NxAZA</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-09-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sEWeeq41k4ohBz4jS_iGRw</td>\n",
       "      <td>tOhOHUAS7XJch7a_HW5Csw</td>\n",
       "      <td>3</td>\n",
       "      <td>EmzaQR5hQlF0WIl24NxAZA</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-04-21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1AqEqmmVHgYCuzcMrF4h2g</td>\n",
       "      <td>2aGafu-x7onydGoDgDfeQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>EmzaQR5hQlF0WIl24NxAZA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-11-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pv82zTlB5Txsu2Pusu__FA</td>\n",
       "      <td>CY4SWiYcUZTWS_T_cGaGPA</td>\n",
       "      <td>4</td>\n",
       "      <td>EmzaQR5hQlF0WIl24NxAZA</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-08-16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jlr3OBS1_Y3Lqa-H3-FR1g</td>\n",
       "      <td>VCKytaG-_YkxmQosH4E0jw</td>\n",
       "      <td>0</td>\n",
       "      <td>EmzaQR5hQlF0WIl24NxAZA</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-12-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id               review_id  votes.cool  \\\n",
       "0  o_LCYay4uo5N4eq3U5pbrQ  biEOCicjWlibF26pNLvhcw           0   \n",
       "1  sEWeeq41k4ohBz4jS_iGRw  tOhOHUAS7XJch7a_HW5Csw           3   \n",
       "2  1AqEqmmVHgYCuzcMrF4h2g  2aGafu-x7onydGoDgDfeQQ           0   \n",
       "3  pv82zTlB5Txsu2Pusu__FA  CY4SWiYcUZTWS_T_cGaGPA           4   \n",
       "4  jlr3OBS1_Y3Lqa-H3-FR1g  VCKytaG-_YkxmQosH4E0jw           0   \n",
       "\n",
       "              business_id  votes.funny  stars        date  votes.useful  \\\n",
       "0  EmzaQR5hQlF0WIl24NxAZA            0      3  2007-09-14             1   \n",
       "1  EmzaQR5hQlF0WIl24NxAZA           12      2  2008-04-21             3   \n",
       "2  EmzaQR5hQlF0WIl24NxAZA            2      2  2009-11-16             0   \n",
       "3  EmzaQR5hQlF0WIl24NxAZA            9      2  2010-08-16             6   \n",
       "4  EmzaQR5hQlF0WIl24NxAZA            1      4  2010-12-04             0   \n",
       "\n",
       "   10 minutes  15 minutes     ...      service great  staff friendly  \\\n",
       "0           0           0     ...                  0               0   \n",
       "1           0           0     ...                  0               0   \n",
       "2           0           0     ...                  0               0   \n",
       "3           0           0     ...                  0               0   \n",
       "4           0           0     ...                  0               0   \n",
       "\n",
       "   super friendly  sweet potato  tasted like  time vegas  try place  ve seen  \\\n",
       "0               0             0            0           0          0        0   \n",
       "1               0             0            0           0          0        0   \n",
       "2               0             0            0           0          0        0   \n",
       "3               0             0            0           0          0        0   \n",
       "4               0             0            0           0          0        0   \n",
       "\n",
       "   ve tried  wait staff  \n",
       "0         0           0  \n",
       "1         0           0  \n",
       "2         0           0  \n",
       "3         0           0  \n",
       "4         0           0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathr = '/Users/paulmartin/Desktop/DSI-SF-2-GitPaulM/datasets/yelp_arizona_data/reviews_small_nlp_parsed.csv'\n",
    "reviews = pd.read_csv(pathr)\n",
    "print reviews.shape\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean up the data a bit -- nulls / columns names\n",
    "new_col = reviews.columns.values\n",
    "new_col = [x.replace(' ','_') for x in new_col]\n",
    "new_col = [x.replace('.','_') for x in new_col]\n",
    "new_col = [x.replace('10','ten') for x in new_col]\n",
    "new_col = [x.replace('15','fifteen') for x in new_col]\n",
    "new_col = [x.replace('20','twenty') for x in new_col]\n",
    "new_col = [x.replace('30','thirty') for x in new_col]\n",
    "\n",
    "reviews.columns = new_col\n",
    "reviews.columns.values\n",
    "reviews.fillna(0,inplace=True)\n",
    "\n",
    "# Eliminate columns with zeroes\n",
    "\n",
    "reviews = reviews.loc[:, (reviews != 0).any(axis=0)] #http://stackoverflow.com/questions/21164910/delete-column-in-pandas-based-on-condition\n",
    "\n",
    "# Columns (since we are here): the patsy formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Going to create two uber rating systems, based on solely the great service and the great food categories only. \n",
    "#The intent is to see if the other predictors are able to predict a great experience and if so by how much\n",
    "#We will not throw out the initial review system.  Rather we will wait that one half of the original weighting\n",
    "#plus  \n",
    "\n",
    "\n",
    "reviews['uber_food'] = reviews['food_amazing'] + reviews['food_great']\n",
    "reviews['uber_service'] = reviews['service_excellent'] + reviews['service_great']\n",
    "\n",
    "reviews['uber_food'] = reviews['uber_food'].map(lambda x: 1 if  x >= 1 else 0) \n",
    "reviews['uber_service'] = reviews['uber_service'].map(lambda x: 1 if x >= 1 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    310848\n",
       "1     11550\n",
       "Name: uber_food, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.uber_food.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18421919319490798"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(reviews.uber_service)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "form_rv=[]\n",
    "[form_rv.append(x) for x in reviews.columns if x not in ['stars','user_id','review_id','business_id','date','uber_food','uber_service','food_amazing','food_great','service_excellent','service_great']]\n",
    "form =  ' + '.join(form_rv)\n",
    "formula_rv_food = 'uber_food ~ ' + form + ' - 1'\n",
    "formula_rv_service = 'uber_service ~ ' + form + ' - 1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>votes_cool</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.660293</td>\n",
       "      <td>1.900567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>votes_funny</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.555918</td>\n",
       "      <td>1.801933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>3.747371</td>\n",
       "      <td>1.303634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>votes_useful</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>1.067631</td>\n",
       "      <td>2.328657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ten_minutes</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.130140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fifteen_minutes</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>0.124089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twenty_minutes</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.118960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirty_minutes</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.105938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar_food</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.095778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer_selection</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>0.101375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_ve</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloody_mary</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.115909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottle_service</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.137061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken_waffles</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.116676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_service</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.030534</td>\n",
       "      <td>0.191487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dance_floor</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.202233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decided_try</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.091188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definitely_come</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.090883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definitely_recommend</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>0.093374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn_want</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008874</td>\n",
       "      <td>0.098116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don_know</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.158810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don_like</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.108171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don_think</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>0.120121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don_want</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.100618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs_benedict</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.104670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_food</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>0.163860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel_like</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.148173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt_like</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.119906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish_chips</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>0.116753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_amazing</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.095701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_great</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>0.117812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_just</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>0.093382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potato_fries</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.012637</td>\n",
       "      <td>0.130714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretty_good</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.204284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_food</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.098208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really_enjoyed</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>0.100078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really_good</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.040261</td>\n",
       "      <td>0.216628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really_like</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.096248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really_nice</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.011737</td>\n",
       "      <td>0.111798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend_place</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.012094</td>\n",
       "      <td>0.109984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red_velvet</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_away</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>0.109868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saturday_night</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.107445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_time</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service_excellent</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.095178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service_food</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.102307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service_friendly</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.089716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service_good</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.138936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service_great</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.026467</td>\n",
       "      <td>0.161887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staff_friendly</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.018254</td>\n",
       "      <td>0.134261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_friendly</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>0.099422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet_potato</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.155694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasted_like</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.129802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_vegas</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>0.095667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>try_place</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>0.099103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve_seen</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.094027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve_tried</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.095387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait_staff</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.108532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber_food</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.035825</td>\n",
       "      <td>0.185855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber_service</th>\n",
       "      <td>322398.0</td>\n",
       "      <td>0.035174</td>\n",
       "      <td>0.184219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count      mean       std  min  25%  50%  75%    max\n",
       "votes_cool            322398.0  0.660293  1.900567  0.0  0.0  0.0  1.0  137.0\n",
       "votes_funny           322398.0  0.555918  1.801933  0.0  0.0  0.0  0.0  129.0\n",
       "stars                 322398.0  3.747371  1.303634  1.0  3.0  4.0  5.0    5.0\n",
       "votes_useful          322398.0  1.067631  2.328657  0.0  0.0  0.0  1.0  141.0\n",
       "ten_minutes           322398.0  0.014063  0.130140  0.0  0.0  0.0  0.0    6.0\n",
       "fifteen_minutes       322398.0  0.012910  0.124089  0.0  0.0  0.0  0.0    7.0\n",
       "twenty_minutes        322398.0  0.012280  0.118960  0.0  0.0  0.0  0.0    4.0\n",
       "thirty_minutes        322398.0  0.009926  0.105938  0.0  0.0  0.0  0.0    4.0\n",
       "bar_food              322398.0  0.007972  0.095778  0.0  0.0  0.0  0.0    5.0\n",
       "beer_selection        322398.0  0.009764  0.101375  0.0  0.0  0.0  0.0    4.0\n",
       "best_ve               322398.0  0.008462  0.093175  0.0  0.0  0.0  0.0    3.0\n",
       "bloody_mary           322398.0  0.008918  0.115909  0.0  0.0  0.0  0.0    7.0\n",
       "bottle_service        322398.0  0.011346  0.137061  0.0  0.0  0.0  0.0    9.0\n",
       "chicken_waffles       322398.0  0.008821  0.116676  0.0  0.0  0.0  0.0    6.0\n",
       "customer_service      322398.0  0.030534  0.191487  0.0  0.0  0.0  0.0    6.0\n",
       "dance_floor           322398.0  0.023400  0.202233  0.0  0.0  0.0  0.0   10.0\n",
       "decided_try           322398.0  0.008108  0.091188  0.0  0.0  0.0  0.0    3.0\n",
       "definitely_come       322398.0  0.008272  0.090883  0.0  0.0  0.0  0.0    2.0\n",
       "definitely_recommend  322398.0  0.008645  0.093374  0.0  0.0  0.0  0.0    2.0\n",
       "didn_want             322398.0  0.008874  0.098116  0.0  0.0  0.0  0.0    5.0\n",
       "don_know              322398.0  0.022962  0.158810  0.0  0.0  0.0  0.0    7.0\n",
       "don_like              322398.0  0.010661  0.108171  0.0  0.0  0.0  0.0    4.0\n",
       "don_think             322398.0  0.013769  0.120121  0.0  0.0  0.0  0.0    3.0\n",
       "don_want              322398.0  0.009166  0.100618  0.0  0.0  0.0  0.0    5.0\n",
       "eggs_benedict         322398.0  0.008238  0.104670  0.0  0.0  0.0  0.0    7.0\n",
       "fast_food             322398.0  0.019017  0.163860  0.0  0.0  0.0  0.0    9.0\n",
       "feel_like             322398.0  0.020289  0.148173  0.0  0.0  0.0  0.0    4.0\n",
       "felt_like             322398.0  0.013384  0.119906  0.0  0.0  0.0  0.0    4.0\n",
       "fish_chips            322398.0  0.008682  0.116753  0.0  0.0  0.0  0.0    7.0\n",
       "food_amazing          322398.0  0.009023  0.095701  0.0  0.0  0.0  0.0    2.0\n",
       "...                        ...       ...       ...  ...  ...  ...  ...    ...\n",
       "place_great           322398.0  0.013778  0.117812  0.0  0.0  0.0  0.0    2.0\n",
       "place_just            322398.0  0.008564  0.093382  0.0  0.0  0.0  0.0    2.0\n",
       "potato_fries          322398.0  0.012637  0.130714  0.0  0.0  0.0  0.0    6.0\n",
       "pretty_good           322398.0  0.036427  0.204284  0.0  0.0  0.0  0.0    7.0\n",
       "quality_food          322398.0  0.009240  0.098208  0.0  0.0  0.0  0.0    3.0\n",
       "really_enjoyed        322398.0  0.009650  0.100078  0.0  0.0  0.0  0.0    3.0\n",
       "really_good           322398.0  0.040261  0.216628  0.0  0.0  0.0  0.0    6.0\n",
       "really_like           322398.0  0.008883  0.096248  0.0  0.0  0.0  0.0    2.0\n",
       "really_nice           322398.0  0.011737  0.111798  0.0  0.0  0.0  0.0    3.0\n",
       "recommend_place       322398.0  0.012094  0.109984  0.0  0.0  0.0  0.0    2.0\n",
       "red_velvet            322398.0  0.011594  0.144338  0.0  0.0  0.0  0.0    9.0\n",
       "right_away            322398.0  0.010906  0.109868  0.0  0.0  0.0  0.0    3.0\n",
       "saturday_night        322398.0  0.010583  0.107445  0.0  0.0  0.0  0.0    4.0\n",
       "second_time           322398.0  0.009032  0.100429  0.0  0.0  0.0  0.0    4.0\n",
       "service_excellent     322398.0  0.009054  0.095178  0.0  0.0  0.0  0.0    2.0\n",
       "service_food          322398.0  0.010357  0.102307  0.0  0.0  0.0  0.0    3.0\n",
       "service_friendly      322398.0  0.008083  0.089716  0.0  0.0  0.0  0.0    2.0\n",
       "service_good          322398.0  0.019349  0.138936  0.0  0.0  0.0  0.0    2.0\n",
       "service_great         322398.0  0.026467  0.161887  0.0  0.0  0.0  0.0    2.0\n",
       "staff_friendly        322398.0  0.018254  0.134261  0.0  0.0  0.0  0.0    2.0\n",
       "super_friendly        322398.0  0.009833  0.099422  0.0  0.0  0.0  0.0    3.0\n",
       "sweet_potato          322398.0  0.017333  0.155694  0.0  0.0  0.0  0.0    8.0\n",
       "tasted_like           322398.0  0.014848  0.129802  0.0  0.0  0.0  0.0    5.0\n",
       "time_vegas            322398.0  0.009042  0.095667  0.0  0.0  0.0  0.0    3.0\n",
       "try_place             322398.0  0.009584  0.099103  0.0  0.0  0.0  0.0    2.0\n",
       "ve_seen               322398.0  0.008195  0.094027  0.0  0.0  0.0  0.0    4.0\n",
       "ve_tried              322398.0  0.008375  0.095387  0.0  0.0  0.0  0.0    3.0\n",
       "wait_staff            322398.0  0.010627  0.108532  0.0  0.0  0.0  0.0    4.0\n",
       "uber_food             322398.0  0.035825  0.185855  0.0  0.0  0.0  0.0    1.0\n",
       "uber_service          322398.0  0.035174  0.184219  0.0  0.0  0.0  0.0    1.0\n",
       "\n",
       "[106 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uber_food ~ votes_cool + votes_funny + votes_useful + ten_minutes + fifteen_minutes + twenty_minutes + thirty_minutes + bar_food + beer_selection + best_ve + bloody_mary + bottle_service + chicken_waffles + customer_service + dance_floor + decided_try + definitely_come + definitely_recommend + didn_want + don_know + don_like + don_think + don_want + eggs_benedict + fast_food + feel_like + felt_like + fish_chips + food_came + food_delicious + food_good + food_just + food_service + french_fries + french_toast + friday_night + fried_chicken + friendly_staff + good_food + good_place + good_service + good_thing + good_time + great_atmosphere + great_experience + great_food + great_place + great_service + great_time + happy_hour + hash_browns + highly_recommend + hip_hop + ice_cream + just_like + just_ok + just_right + las_vegas + late_night + like_place + little_bit + long_time + looked_like + looks_like + love_place + mac_cheese + make_sure + mashed_potatoes + medium_rare + minutes_later + new_york + onion_rings + place_good + place_great + place_just + potato_fries + pretty_good + quality_food + really_enjoyed + really_good + really_like + really_nice + recommend_place + red_velvet + right_away + saturday_night + second_time + service_food + service_friendly + service_good + staff_friendly + super_friendly + sweet_potato + tasted_like + time_vegas + try_place + ve_seen + ve_tried + wait_staff - 1\n"
     ]
    }
   ],
   "source": [
    "print formula_rv_food\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle/stratify, # get a decent sample size\n",
    "reviews = reviews.sample(frac=1).reset_index(drop=True)\n",
    "reviews.reset_index()\n",
    "#http://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "reviews_sample = reviews[0:40000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000, 99)\n"
     ]
    }
   ],
   "source": [
    "#patsy, ravel\n",
    "y,X = patsy.dmatrices(formula_rv_food, data=reviews_sample, return_type='dataframe')\n",
    "y = np.ravel(y)\n",
    "print y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Food:\n",
      "Scores:  [0.96400899775056237, 0.96375906023494129, 0.96500874781304669, 0.96575856035991003, 0.96600849787553111, 0.96374093523380844, 0.96524131032758187, 0.96249062265566387, 0.96274068517129285, 0.96574143535883972]\n",
      "Scores mean:  0.964449885278\n",
      "Baseline accuracy: 0.035375\n"
     ]
    }
   ],
   "source": [
    "#Train / test\n",
    "\n",
    "cv_indices = StratifiedKFold(y, n_folds=10)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "lr_scores = []\n",
    "\n",
    "#Train / Test loop\n",
    "for traini, testi in cv_indices:\n",
    "    Xtr, ytr  = X.iloc[traini, :], y[traini]\n",
    "    Xte, yte =  X.iloc[testi, :], y[testi]\n",
    "    logreg.fit(Xtr, ytr)\n",
    "    lr_scores.append(logreg.score(Xte, yte))   \n",
    "\n",
    "print 'Logistic Regression Food:'\n",
    "print \"Scores: \", lr_scores\n",
    "print \"Scores mean: \", np.mean(lr_scores)\n",
    "\n",
    "print 'Baseline accuracy:', np.mean(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98     38585\n",
      "        1.0       0.55      0.07      0.12      1415\n",
      "\n",
      "avg / total       0.95      0.97      0.95     40000\n",
      "\n",
      "Predicted    0.0  1.0    All\n",
      "Actual                      \n",
      "0.0        38509   76  38585\n",
      "1.0         1323   92   1415\n",
      "All        39832  168  40000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = logreg.predict(X)\n",
    "\n",
    "print \"Classification Report\"\n",
    "cls_rep = classification_report(y, y_pred)\n",
    "print cls_rep\n",
    "confusion = pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food_abs_coef' 'food_coef' 'variable']\n"
     ]
    }
   ],
   "source": [
    "ls = X.columns.values.tolist()\n",
    "coefs_food = pd.DataFrame({'variable':ls,'coef':logreg.coef_[0], 'abs_coef':np.abs(logreg.coef_[0])})\n",
    "coefs_food.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "coefs_food.rename(columns = {'coef': 'food_coef', 'abs_coef':'food_abs_coef' },inplace=True)\n",
    "print coefs_food.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_abs_coef</th>\n",
       "      <th>food_coef</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.001932</td>\n",
       "      <td>2.001932</td>\n",
       "      <td>great_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.724599</td>\n",
       "      <td>1.724599</td>\n",
       "      <td>great_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.444005</td>\n",
       "      <td>1.444005</td>\n",
       "      <td>great_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.126614</td>\n",
       "      <td>-1.126614</td>\n",
       "      <td>bottle_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.110019</td>\n",
       "      <td>-1.110019</td>\n",
       "      <td>dance_floor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    food_abs_coef  food_coef          variable\n",
       "47       2.001932   2.001932     great_service\n",
       "45       1.724599   1.724599        great_food\n",
       "43       1.444005   1.444005  great_atmosphere\n",
       "11       1.126614  -1.126614    bottle_service\n",
       "14       1.110019  -1.110019       dance_floor"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_food.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Service:\n",
      "Scores:  [0.96575, 0.96599999999999997, 0.96575, 0.96550000000000002, 0.96499999999999997, 0.96599999999999997, 0.96625000000000005, 0.96550000000000002, 0.96575, 0.96525000000000005]\n",
      "Scores mean:  0.965675\n",
      "Baseline accuracy: 0.034\n"
     ]
    }
   ],
   "source": [
    "# patsy, ravel and then cross validate for the first rating: uber_service\n",
    "\n",
    "y,X = patsy.dmatrices(formula_rv_service, data=reviews_sample, return_type='dataframe')\n",
    "y = np.ravel(y)\n",
    "\n",
    "cv_indices = StratifiedKFold(y, n_folds=10)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "lr_scores = []\n",
    "\n",
    "#Train / Test loop\n",
    "for traini, testi in cv_indices:\n",
    "    Xtr, ytr  = X.iloc[traini, :], y[traini]\n",
    "    Xte, yte =  X.iloc[testi, :], y[testi]\n",
    "    logreg.fit(Xtr, ytr)\n",
    "    lr_scores.append(logreg.score(Xte, yte))   \n",
    "\n",
    "print 'Logistic Regression Service:'\n",
    "print \"Scores: \", lr_scores\n",
    "print \"Scores mean: \", np.mean(lr_scores)\n",
    "print 'Baseline accuracy:', np.mean(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98     38640\n",
      "        1.0       0.40      0.01      0.03      1360\n",
      "\n",
      "avg / total       0.95      0.97      0.95     40000\n",
      "\n",
      "Predicted    0.0  1.0    All\n",
      "Actual                      \n",
      "0.0        38613   27  38640\n",
      "1.0         1342   18   1360\n",
      "All        39955   45  40000\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X)\n",
    "\n",
    "print \"Classification Report\"\n",
    "cls_rep = classification_report(y, y_pred)\n",
    "print cls_rep\n",
    "confusion = pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefs_service = pd.DataFrame({'variable':ls,'coef':logreg.coef_[0], 'abs_coef':np.abs(logreg.coef_[0])})\n",
    "coefs_service.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "coefs_service.rename(columns={'coef': \"service_coef\", 'abs_coef':'service_abs_coef' },inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_abs_coef</th>\n",
       "      <th>food_coef</th>\n",
       "      <th>variable</th>\n",
       "      <th>service_abs_coef</th>\n",
       "      <th>service_coef</th>\n",
       "      <th>coefficient_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.001932</td>\n",
       "      <td>2.001932</td>\n",
       "      <td>great_service</td>\n",
       "      <td>1.522668</td>\n",
       "      <td>1.522668</td>\n",
       "      <td>0.479264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.724599</td>\n",
       "      <td>1.724599</td>\n",
       "      <td>great_food</td>\n",
       "      <td>1.484495</td>\n",
       "      <td>1.484495</td>\n",
       "      <td>0.240104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.444005</td>\n",
       "      <td>1.444005</td>\n",
       "      <td>great_atmosphere</td>\n",
       "      <td>0.808145</td>\n",
       "      <td>0.808145</td>\n",
       "      <td>0.635859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.126614</td>\n",
       "      <td>-1.126614</td>\n",
       "      <td>bottle_service</td>\n",
       "      <td>0.263263</td>\n",
       "      <td>0.263263</td>\n",
       "      <td>-1.389877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.110019</td>\n",
       "      <td>-1.110019</td>\n",
       "      <td>dance_floor</td>\n",
       "      <td>0.379202</td>\n",
       "      <td>-0.379202</td>\n",
       "      <td>-0.730817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.097004</td>\n",
       "      <td>1.097004</td>\n",
       "      <td>good_food</td>\n",
       "      <td>0.342609</td>\n",
       "      <td>-0.342609</td>\n",
       "      <td>1.439613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.983395</td>\n",
       "      <td>-0.983395</td>\n",
       "      <td>pretty_good</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>-0.066187</td>\n",
       "      <td>-0.917209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.925114</td>\n",
       "      <td>-0.925114</td>\n",
       "      <td>like_place</td>\n",
       "      <td>0.142190</td>\n",
       "      <td>-0.142190</td>\n",
       "      <td>-0.782923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.917924</td>\n",
       "      <td>0.917924</td>\n",
       "      <td>quality_food</td>\n",
       "      <td>0.208229</td>\n",
       "      <td>0.208229</td>\n",
       "      <td>0.709695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.802525</td>\n",
       "      <td>-0.802525</td>\n",
       "      <td>hip_hop</td>\n",
       "      <td>0.753467</td>\n",
       "      <td>-0.753467</td>\n",
       "      <td>-0.049058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.715639</td>\n",
       "      <td>-0.715639</td>\n",
       "      <td>food_good</td>\n",
       "      <td>0.360050</td>\n",
       "      <td>0.360050</td>\n",
       "      <td>-1.075689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.697413</td>\n",
       "      <td>0.697413</td>\n",
       "      <td>definitely_recommend</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>-0.120499</td>\n",
       "      <td>0.817912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.656326</td>\n",
       "      <td>-0.656326</td>\n",
       "      <td>looked_like</td>\n",
       "      <td>0.668341</td>\n",
       "      <td>-0.668341</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.637457</td>\n",
       "      <td>0.637457</td>\n",
       "      <td>place_good</td>\n",
       "      <td>0.357876</td>\n",
       "      <td>-0.357876</td>\n",
       "      <td>0.995333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.626963</td>\n",
       "      <td>0.626963</td>\n",
       "      <td>great_time</td>\n",
       "      <td>0.176059</td>\n",
       "      <td>0.176059</td>\n",
       "      <td>0.450904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.602639</td>\n",
       "      <td>0.602639</td>\n",
       "      <td>great_experience</td>\n",
       "      <td>0.559619</td>\n",
       "      <td>0.559619</td>\n",
       "      <td>0.043020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.597893</td>\n",
       "      <td>-0.597893</td>\n",
       "      <td>really_like</td>\n",
       "      <td>0.560494</td>\n",
       "      <td>-0.560494</td>\n",
       "      <td>-0.037399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.577294</td>\n",
       "      <td>-0.577294</td>\n",
       "      <td>just_ok</td>\n",
       "      <td>0.032696</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.544598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.496363</td>\n",
       "      <td>-0.496363</td>\n",
       "      <td>tasted_like</td>\n",
       "      <td>0.242470</td>\n",
       "      <td>-0.242470</td>\n",
       "      <td>-0.253893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.494335</td>\n",
       "      <td>-0.494335</td>\n",
       "      <td>just_like</td>\n",
       "      <td>0.242705</td>\n",
       "      <td>0.242705</td>\n",
       "      <td>-0.737039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.482450</td>\n",
       "      <td>0.482450</td>\n",
       "      <td>ve_seen</td>\n",
       "      <td>0.251409</td>\n",
       "      <td>-0.251409</td>\n",
       "      <td>0.733859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.477243</td>\n",
       "      <td>-0.477243</td>\n",
       "      <td>food_delicious</td>\n",
       "      <td>1.235798</td>\n",
       "      <td>1.235798</td>\n",
       "      <td>-1.713041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.451809</td>\n",
       "      <td>0.451809</td>\n",
       "      <td>love_place</td>\n",
       "      <td>0.169844</td>\n",
       "      <td>0.169844</td>\n",
       "      <td>0.281965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.444572</td>\n",
       "      <td>0.444572</td>\n",
       "      <td>staff_friendly</td>\n",
       "      <td>0.736636</td>\n",
       "      <td>-0.736636</td>\n",
       "      <td>1.181208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.442249</td>\n",
       "      <td>-0.442249</td>\n",
       "      <td>fifteen_minutes</td>\n",
       "      <td>0.378936</td>\n",
       "      <td>-0.378936</td>\n",
       "      <td>-0.063313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.436660</td>\n",
       "      <td>-0.436660</td>\n",
       "      <td>place_just</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>-0.090820</td>\n",
       "      <td>-0.345840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.391844</td>\n",
       "      <td>-0.391844</td>\n",
       "      <td>bloody_mary</td>\n",
       "      <td>0.302929</td>\n",
       "      <td>0.302929</td>\n",
       "      <td>-0.694773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.391818</td>\n",
       "      <td>-0.391818</td>\n",
       "      <td>food_just</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>-0.634718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.391228</td>\n",
       "      <td>0.391228</td>\n",
       "      <td>service_friendly</td>\n",
       "      <td>1.381666</td>\n",
       "      <td>-1.381666</td>\n",
       "      <td>1.772894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.385087</td>\n",
       "      <td>-0.385087</td>\n",
       "      <td>new_york</td>\n",
       "      <td>0.217939</td>\n",
       "      <td>-0.217939</td>\n",
       "      <td>-0.167148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.122748</td>\n",
       "      <td>-0.122748</td>\n",
       "      <td>little_bit</td>\n",
       "      <td>0.412985</td>\n",
       "      <td>0.412985</td>\n",
       "      <td>-0.535732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.118241</td>\n",
       "      <td>-0.118241</td>\n",
       "      <td>fried_chicken</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>-0.196855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.116931</td>\n",
       "      <td>0.116931</td>\n",
       "      <td>mac_cheese</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>-0.258172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.114078</td>\n",
       "      <td>0.114078</td>\n",
       "      <td>bar_food</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>-0.078739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.111150</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>votes_cool</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>-0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.109832</td>\n",
       "      <td>-0.109832</td>\n",
       "      <td>friday_night</td>\n",
       "      <td>0.196033</td>\n",
       "      <td>-0.196033</td>\n",
       "      <td>0.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.101896</td>\n",
       "      <td>0.101896</td>\n",
       "      <td>food_came</td>\n",
       "      <td>0.335825</td>\n",
       "      <td>0.335825</td>\n",
       "      <td>-0.233929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.101002</td>\n",
       "      <td>-0.101002</td>\n",
       "      <td>votes_useful</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>-0.067982</td>\n",
       "      <td>-0.033020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.092205</td>\n",
       "      <td>-0.092205</td>\n",
       "      <td>don_know</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>-0.150624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.088670</td>\n",
       "      <td>-0.088670</td>\n",
       "      <td>feel_like</td>\n",
       "      <td>0.136166</td>\n",
       "      <td>-0.136166</td>\n",
       "      <td>0.047495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.087594</td>\n",
       "      <td>0.087594</td>\n",
       "      <td>really_nice</td>\n",
       "      <td>0.184185</td>\n",
       "      <td>0.184185</td>\n",
       "      <td>-0.096591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.086665</td>\n",
       "      <td>-0.086665</td>\n",
       "      <td>votes_funny</td>\n",
       "      <td>0.141250</td>\n",
       "      <td>-0.141250</td>\n",
       "      <td>0.054585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.085153</td>\n",
       "      <td>-0.085153</td>\n",
       "      <td>onion_rings</td>\n",
       "      <td>0.116254</td>\n",
       "      <td>-0.116254</td>\n",
       "      <td>0.031101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.079061</td>\n",
       "      <td>-0.079061</td>\n",
       "      <td>good_time</td>\n",
       "      <td>0.036355</td>\n",
       "      <td>0.036355</td>\n",
       "      <td>-0.115416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.070346</td>\n",
       "      <td>-0.070346</td>\n",
       "      <td>potato_fries</td>\n",
       "      <td>0.589443</td>\n",
       "      <td>0.589443</td>\n",
       "      <td>-0.659789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.063257</td>\n",
       "      <td>0.063257</td>\n",
       "      <td>long_time</td>\n",
       "      <td>0.071586</td>\n",
       "      <td>-0.071586</td>\n",
       "      <td>0.134843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.057031</td>\n",
       "      <td>-0.057031</td>\n",
       "      <td>really_good</td>\n",
       "      <td>0.021508</td>\n",
       "      <td>-0.021508</td>\n",
       "      <td>-0.035523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.055024</td>\n",
       "      <td>0.055024</td>\n",
       "      <td>don_want</td>\n",
       "      <td>0.030685</td>\n",
       "      <td>0.030685</td>\n",
       "      <td>0.024339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.053876</td>\n",
       "      <td>decided_try</td>\n",
       "      <td>0.442853</td>\n",
       "      <td>0.442853</td>\n",
       "      <td>-0.388977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.050611</td>\n",
       "      <td>-0.050611</td>\n",
       "      <td>friendly_staff</td>\n",
       "      <td>0.530695</td>\n",
       "      <td>-0.530695</td>\n",
       "      <td>0.480084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.041832</td>\n",
       "      <td>-0.041832</td>\n",
       "      <td>twenty_minutes</td>\n",
       "      <td>0.759971</td>\n",
       "      <td>-0.759971</td>\n",
       "      <td>0.718139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.036032</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>french_toast</td>\n",
       "      <td>0.417147</td>\n",
       "      <td>0.417147</td>\n",
       "      <td>-0.381115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.032273</td>\n",
       "      <td>0.032273</td>\n",
       "      <td>fish_chips</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>-0.304946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.030428</td>\n",
       "      <td>-0.030428</td>\n",
       "      <td>happy_hour</td>\n",
       "      <td>0.146562</td>\n",
       "      <td>0.146562</td>\n",
       "      <td>-0.176989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.019955</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>wait_staff</td>\n",
       "      <td>0.198597</td>\n",
       "      <td>-0.198597</td>\n",
       "      <td>0.218551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.013671</td>\n",
       "      <td>-0.013671</td>\n",
       "      <td>definitely_come</td>\n",
       "      <td>0.682452</td>\n",
       "      <td>0.682452</td>\n",
       "      <td>-0.696123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.012895</td>\n",
       "      <td>-0.012895</td>\n",
       "      <td>sweet_potato</td>\n",
       "      <td>0.244902</td>\n",
       "      <td>-0.244902</td>\n",
       "      <td>0.232007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.012520</td>\n",
       "      <td>-0.012520</td>\n",
       "      <td>looks_like</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>-0.016884</td>\n",
       "      <td>0.004364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.003413</td>\n",
       "      <td>-0.003413</td>\n",
       "      <td>good_service</td>\n",
       "      <td>1.509286</td>\n",
       "      <td>1.509286</td>\n",
       "      <td>-1.512698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>beer_selection</td>\n",
       "      <td>0.468544</td>\n",
       "      <td>-0.468544</td>\n",
       "      <td>0.469893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    food_abs_coef  food_coef              variable  service_abs_coef  \\\n",
       "0        2.001932   2.001932         great_service          1.522668   \n",
       "1        1.724599   1.724599            great_food          1.484495   \n",
       "2        1.444005   1.444005      great_atmosphere          0.808145   \n",
       "3        1.126614  -1.126614        bottle_service          0.263263   \n",
       "4        1.110019  -1.110019           dance_floor          0.379202   \n",
       "5        1.097004   1.097004             good_food          0.342609   \n",
       "6        0.983395  -0.983395           pretty_good          0.066187   \n",
       "7        0.925114  -0.925114            like_place          0.142190   \n",
       "8        0.917924   0.917924          quality_food          0.208229   \n",
       "9        0.802525  -0.802525               hip_hop          0.753467   \n",
       "10       0.715639  -0.715639             food_good          0.360050   \n",
       "11       0.697413   0.697413  definitely_recommend          0.120499   \n",
       "12       0.656326  -0.656326           looked_like          0.668341   \n",
       "13       0.637457   0.637457            place_good          0.357876   \n",
       "14       0.626963   0.626963            great_time          0.176059   \n",
       "15       0.602639   0.602639      great_experience          0.559619   \n",
       "16       0.597893  -0.597893           really_like          0.560494   \n",
       "17       0.577294  -0.577294               just_ok          0.032696   \n",
       "18       0.496363  -0.496363           tasted_like          0.242470   \n",
       "19       0.494335  -0.494335             just_like          0.242705   \n",
       "20       0.482450   0.482450               ve_seen          0.251409   \n",
       "21       0.477243  -0.477243        food_delicious          1.235798   \n",
       "22       0.451809   0.451809            love_place          0.169844   \n",
       "23       0.444572   0.444572        staff_friendly          0.736636   \n",
       "24       0.442249  -0.442249       fifteen_minutes          0.378936   \n",
       "25       0.436660  -0.436660            place_just          0.090820   \n",
       "26       0.391844  -0.391844           bloody_mary          0.302929   \n",
       "27       0.391818  -0.391818             food_just          0.242900   \n",
       "28       0.391228   0.391228      service_friendly          1.381666   \n",
       "29       0.385087  -0.385087              new_york          0.217939   \n",
       "..            ...        ...                   ...               ...   \n",
       "69       0.122748  -0.122748            little_bit          0.412985   \n",
       "70       0.118241  -0.118241         fried_chicken          0.078613   \n",
       "71       0.116931   0.116931            mac_cheese          0.375103   \n",
       "72       0.114078   0.114078              bar_food          0.192817   \n",
       "73       0.111150   0.111150            votes_cool          0.132700   \n",
       "74       0.109832  -0.109832          friday_night          0.196033   \n",
       "75       0.101896   0.101896             food_came          0.335825   \n",
       "76       0.101002  -0.101002          votes_useful          0.067982   \n",
       "77       0.092205  -0.092205              don_know          0.058419   \n",
       "78       0.088670  -0.088670             feel_like          0.136166   \n",
       "79       0.087594   0.087594           really_nice          0.184185   \n",
       "80       0.086665  -0.086665           votes_funny          0.141250   \n",
       "81       0.085153  -0.085153           onion_rings          0.116254   \n",
       "82       0.079061  -0.079061             good_time          0.036355   \n",
       "83       0.070346  -0.070346          potato_fries          0.589443   \n",
       "84       0.063257   0.063257             long_time          0.071586   \n",
       "85       0.057031  -0.057031           really_good          0.021508   \n",
       "86       0.055024   0.055024              don_want          0.030685   \n",
       "87       0.053876   0.053876           decided_try          0.442853   \n",
       "88       0.050611  -0.050611        friendly_staff          0.530695   \n",
       "89       0.041832  -0.041832        twenty_minutes          0.759971   \n",
       "90       0.036032   0.036032          french_toast          0.417147   \n",
       "91       0.032273   0.032273            fish_chips          0.337218   \n",
       "92       0.030428  -0.030428            happy_hour          0.146562   \n",
       "93       0.019955   0.019955            wait_staff          0.198597   \n",
       "94       0.013671  -0.013671       definitely_come          0.682452   \n",
       "95       0.012895  -0.012895          sweet_potato          0.244902   \n",
       "96       0.012520  -0.012520            looks_like          0.016884   \n",
       "97       0.003413  -0.003413          good_service          1.509286   \n",
       "98       0.001349   0.001349        beer_selection          0.468544   \n",
       "\n",
       "    service_coef  coefficient_difference  \n",
       "0       1.522668                0.479264  \n",
       "1       1.484495                0.240104  \n",
       "2       0.808145                0.635859  \n",
       "3       0.263263               -1.389877  \n",
       "4      -0.379202               -0.730817  \n",
       "5      -0.342609                1.439613  \n",
       "6      -0.066187               -0.917209  \n",
       "7      -0.142190               -0.782923  \n",
       "8       0.208229                0.709695  \n",
       "9      -0.753467               -0.049058  \n",
       "10      0.360050               -1.075689  \n",
       "11     -0.120499                0.817912  \n",
       "12     -0.668341                0.012015  \n",
       "13     -0.357876                0.995333  \n",
       "14      0.176059                0.450904  \n",
       "15      0.559619                0.043020  \n",
       "16     -0.560494               -0.037399  \n",
       "17     -0.032696               -0.544598  \n",
       "18     -0.242470               -0.253893  \n",
       "19      0.242705               -0.737039  \n",
       "20     -0.251409                0.733859  \n",
       "21      1.235798               -1.713041  \n",
       "22      0.169844                0.281965  \n",
       "23     -0.736636                1.181208  \n",
       "24     -0.378936               -0.063313  \n",
       "25     -0.090820               -0.345840  \n",
       "26      0.302929               -0.694773  \n",
       "27      0.242900               -0.634718  \n",
       "28     -1.381666                1.772894  \n",
       "29     -0.217939               -0.167148  \n",
       "..           ...                     ...  \n",
       "69      0.412985               -0.535732  \n",
       "70      0.078613               -0.196855  \n",
       "71      0.375103               -0.258172  \n",
       "72      0.192817               -0.078739  \n",
       "73      0.132700               -0.021550  \n",
       "74     -0.196033                0.086200  \n",
       "75      0.335825               -0.233929  \n",
       "76     -0.067982               -0.033020  \n",
       "77      0.058419               -0.150624  \n",
       "78     -0.136166                0.047495  \n",
       "79      0.184185               -0.096591  \n",
       "80     -0.141250                0.054585  \n",
       "81     -0.116254                0.031101  \n",
       "82      0.036355               -0.115416  \n",
       "83      0.589443               -0.659789  \n",
       "84     -0.071586                0.134843  \n",
       "85     -0.021508               -0.035523  \n",
       "86      0.030685                0.024339  \n",
       "87      0.442853               -0.388977  \n",
       "88     -0.530695                0.480084  \n",
       "89     -0.759971                0.718139  \n",
       "90      0.417147               -0.381115  \n",
       "91      0.337218               -0.304946  \n",
       "92      0.146562               -0.176989  \n",
       "93     -0.198597                0.218551  \n",
       "94      0.682452               -0.696123  \n",
       "95     -0.244902                0.232007  \n",
       "96     -0.016884                0.004364  \n",
       "97      1.509286               -1.512698  \n",
       "98     -0.468544                0.469893  \n",
       "\n",
       "[99 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the coefficients, check out the difference\n",
    "\n",
    "result = pd.merge(coefs_food, coefs_service, on='variable', how='inner')\n",
    "result['coefficient_difference'] = result['food_coef'] - result['service_coef']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# difference in coefficients:  Models appear to be the same.  Likely a bad design of creating the ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. Identifying \"elite\" users\n",
    "\n",
    "---\n",
    "\n",
    "Yelp, though having their own formula for determining whether a user is elite or not, is interested in delving deeper into what differentiates an elite user from a normal user at a broader level.\n",
    "\n",
    "Use a classification model to predict whether a user is elite or not. Note that users can be elite in some years and not in others.\n",
    "\n",
    "1. What things predict well whether a user is elite or not?\n",
    "- Validate the model.\n",
    "- If you were to remove the \"counts\" metrics for users (reviews, votes, compliments), what distinguishes an elite user, if anything? Validate the model and compare it to the one with the count variables.\n",
    "- Think of a way to visually represent your results in a compelling way.\n",
    "- Give a brief write-up of your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144206, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144206 entries, 0 to 144205\n",
      "Data columns (total 21 columns):\n",
      "yelping_since          144206 non-null object\n",
      "compliments.plain      47034 non-null float64\n",
      "review_count           144206 non-null int64\n",
      "compliments.cute       13133 non-null float64\n",
      "compliments.writer     33222 non-null float64\n",
      "fans                   144206 non-null int64\n",
      "compliments.note       39872 non-null float64\n",
      "compliments.hot        31748 non-null float64\n",
      "compliments.cool       41069 non-null float64\n",
      "compliments.profile    12368 non-null float64\n",
      "average_stars          144206 non-null float64\n",
      "compliments.more       25066 non-null float64\n",
      "elite                  144206 non-null object\n",
      "name                   144206 non-null object\n",
      "user_id                144206 non-null object\n",
      "votes.cool             144206 non-null int64\n",
      "compliments.list       7180 non-null float64\n",
      "votes.funny            144206 non-null int64\n",
      "compliments.photos     18759 non-null float64\n",
      "compliments.funny      30612 non-null float64\n",
      "votes.useful           144206 non-null int64\n",
      "dtypes: float64(12), int64(5), object(4)\n",
      "memory usage: 23.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Approach here will be to set up a new field for Elite and use \n",
    "#KNN classification algorithm to find a fit\n",
    "\n",
    "pathux = '/Users/paulmartin/Desktop/DSI-SF-2-GitPaulM/datasets/yelp_arizona_data/users_small_parsed.csv'\n",
    "ux = pd.read_csv(pathux)\n",
    "print ux.shape\n",
    "ux.loc[0,'elite']\n",
    "ux.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux.loc[0,'elite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intinlist(x):\n",
    "#    print x\n",
    "    z=[]\n",
    "    try:\n",
    "        z = (x.replace(\"]\",\"\").replace(\"[\",\"\").split(\",\"))\n",
    "#        print z\n",
    "        z = [int(i) for i in z]\n",
    "#        print z\n",
    "        return z\n",
    "    except:\n",
    "        z = []\n",
    "        return z\n",
    "    \n",
    "ystr = '[2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]'\n",
    "ystr = '[]'\n",
    "\n",
    "#y = intinlist(ystr)\n",
    "#y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just in case\n",
    "ux['elite'] = ux['elite'].map(intinlist)\n",
    "\n",
    "#results = [int(i) for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>compliments.plain</th>\n",
       "      <th>review_count</th>\n",
       "      <th>compliments.cute</th>\n",
       "      <th>compliments.writer</th>\n",
       "      <th>fans</th>\n",
       "      <th>compliments.note</th>\n",
       "      <th>compliments.hot</th>\n",
       "      <th>compliments.cool</th>\n",
       "      <th>compliments.profile</th>\n",
       "      <th>...</th>\n",
       "      <th>compliments.more</th>\n",
       "      <th>elite</th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes.cool</th>\n",
       "      <th>compliments.list</th>\n",
       "      <th>votes.funny</th>\n",
       "      <th>compliments.photos</th>\n",
       "      <th>compliments.funny</th>\n",
       "      <th>votes.useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-10</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1274</td>\n",
       "      <td>206.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>1179</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>[2005, 2006, 2007, 2008, 2009, 2010, 2011, 201...</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>rpOyqD_893cqmDAtJLbdog</td>\n",
       "      <td>11093</td>\n",
       "      <td>38.0</td>\n",
       "      <td>7681</td>\n",
       "      <td>330.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>14199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10</td>\n",
       "      <td>89.0</td>\n",
       "      <td>442</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100</td>\n",
       "      <td>83.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[2005, 2006, 2007, 2008, 2009, 2010, 2011, 201...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>4U9kSBLuBDU391x6bxU-YA</td>\n",
       "      <td>732</td>\n",
       "      <td>4.0</td>\n",
       "      <td>908</td>\n",
       "      <td>24.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2005]</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>SIBCL7HBkrP4llolm4SC2A</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Nader</td>\n",
       "      <td>UTS9XcT14H2ZscRIf0MYHQ</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-10</td>\n",
       "      <td>104.0</td>\n",
       "      <td>983</td>\n",
       "      <td>82.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>78</td>\n",
       "      <td>85.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[2005, 2006, 2007, 2008, 2010, 2011, 2012]</td>\n",
       "      <td>Helen</td>\n",
       "      <td>ZWOj6LmzwGvMDh-A85EOtA</td>\n",
       "      <td>1928</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1109</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  yelping_since  compliments.plain  review_count  compliments.cute  \\\n",
       "0       2004-10              959.0          1274             206.0   \n",
       "1       2004-10               89.0           442              23.0   \n",
       "2       2004-10                2.0            66               2.0   \n",
       "3       2004-10                5.0           101               1.0   \n",
       "4       2004-10              104.0           983              82.0   \n",
       "\n",
       "   compliments.writer  fans  compliments.note  compliments.hot  \\\n",
       "0               327.0  1179             611.0           1094.0   \n",
       "1                24.0   100              83.0            101.0   \n",
       "2                 2.0     4               1.0              1.0   \n",
       "3                 3.0     7               3.0              5.0   \n",
       "4                17.0    78              85.0            265.0   \n",
       "\n",
       "   compliments.cool  compliments.profile      ...       compliments.more  \\\n",
       "0            1642.0                116.0      ...                  134.0   \n",
       "1             145.0                  9.0      ...                   19.0   \n",
       "2               1.0                  NaN      ...                    1.0   \n",
       "3               4.0                  1.0      ...                    2.0   \n",
       "4             212.0                  9.0      ...                   16.0   \n",
       "\n",
       "                                               elite       name  \\\n",
       "0  [2005, 2006, 2007, 2008, 2009, 2010, 2011, 201...     Jeremy   \n",
       "1  [2005, 2006, 2007, 2008, 2009, 2010, 2011, 201...    Michael   \n",
       "2                                             [2005]  Katherine   \n",
       "3                                                 []      Nader   \n",
       "4         [2005, 2006, 2007, 2008, 2010, 2011, 2012]      Helen   \n",
       "\n",
       "                  user_id votes.cool  compliments.list  votes.funny  \\\n",
       "0  rpOyqD_893cqmDAtJLbdog      11093              38.0         7681   \n",
       "1  4U9kSBLuBDU391x6bxU-YA        732               4.0          908   \n",
       "2  SIBCL7HBkrP4llolm4SC2A         13               NaN           11   \n",
       "3  UTS9XcT14H2ZscRIf0MYHQ         49               NaN           53   \n",
       "4  ZWOj6LmzwGvMDh-A85EOtA       1928               3.0         1109   \n",
       "\n",
       "   compliments.photos  compliments.funny  votes.useful  \n",
       "0               330.0              580.0         14199  \n",
       "1                24.0              120.0          1483  \n",
       "2                 NaN                NaN            34  \n",
       "3                 1.0                8.0           243  \n",
       "4                57.0               70.0          2404  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux.loc[3,'elite']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_level = 1\n",
    "ux['elite_flag'] = ux['elite'].map(lambda x: 1 if len(x) >= elite_level else 0)\n",
    "ux['elite_years'] = ux['elite'].map(lambda x: len(x))\n",
    "ux.rename(columns=lambda x: x.replace(' ', '_').replace('.', '_'),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compliments_plain</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>11.167580</td>\n",
       "      <td>145.287346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_count</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>54.968649</td>\n",
       "      <td>138.452373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>8529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_cute</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>0.790577</td>\n",
       "      <td>12.888196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_writer</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>4.260211</td>\n",
       "      <td>49.650805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fans</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>2.958275</td>\n",
       "      <td>17.657132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_note</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>4.646818</td>\n",
       "      <td>48.503054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_hot</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>8.402972</td>\n",
       "      <td>103.066822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_cool</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>11.412639</td>\n",
       "      <td>128.795241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_profile</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>0.770079</td>\n",
       "      <td>23.244386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_stars</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>3.768235</td>\n",
       "      <td>0.824896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4.26</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_more</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>1.065718</td>\n",
       "      <td>16.130503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>votes_cool</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>69.739206</td>\n",
       "      <td>559.165052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>37288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_list</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>0.370290</td>\n",
       "      <td>9.603909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>votes_funny</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>61.038057</td>\n",
       "      <td>500.056636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>36462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_photos</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>2.555199</td>\n",
       "      <td>71.099615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliments_funny</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>5.183016</td>\n",
       "      <td>69.407738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>votes_useful</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>115.904824</td>\n",
       "      <td>671.365974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>42047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elite_flag</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>0.319352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elite_years</th>\n",
       "      <td>144206.0</td>\n",
       "      <td>0.362953</td>\n",
       "      <td>1.199497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count        mean         std  min  25%    50%    75%  \\\n",
       "compliments_plain    144206.0   11.167580  145.287346  0.0  0.0   0.00   1.00   \n",
       "review_count         144206.0   54.968649  138.452373  0.0  5.0  13.00  42.00   \n",
       "compliments_cute     144206.0    0.790577   12.888196  0.0  0.0   0.00   0.00   \n",
       "compliments_writer   144206.0    4.260211   49.650805  0.0  0.0   0.00   0.00   \n",
       "fans                 144206.0    2.958275   17.657132  0.0  0.0   0.00   1.00   \n",
       "compliments_note     144206.0    4.646818   48.503054  0.0  0.0   0.00   1.00   \n",
       "compliments_hot      144206.0    8.402972  103.066822  0.0  0.0   0.00   0.00   \n",
       "compliments_cool     144206.0   11.412639  128.795241  0.0  0.0   0.00   1.00   \n",
       "compliments_profile  144206.0    0.770079   23.244386  0.0  0.0   0.00   0.00   \n",
       "average_stars        144206.0    3.768235    0.824896  0.0  3.4   3.84   4.26   \n",
       "compliments_more     144206.0    1.065718   16.130503  0.0  0.0   0.00   0.00   \n",
       "votes_cool           144206.0   69.739206  559.165052  0.0  0.0   3.00  15.00   \n",
       "compliments_list     144206.0    0.370290    9.603909  0.0  0.0   0.00   0.00   \n",
       "votes_funny          144206.0   61.038057  500.056636  0.0  0.0   3.00  14.00   \n",
       "compliments_photos   144206.0    2.555199   71.099615  0.0  0.0   0.00   0.00   \n",
       "compliments_funny    144206.0    5.183016   69.407738  0.0  0.0   0.00   0.00   \n",
       "votes_useful         144206.0  115.904824  671.365974  0.0  3.0  11.00  47.00   \n",
       "elite_flag           144206.0    0.115273    0.319352  0.0  0.0   0.00   0.00   \n",
       "elite_years          144206.0    0.362953    1.199497  0.0  0.0   0.00   0.00   \n",
       "\n",
       "                         max  \n",
       "compliments_plain    13129.0  \n",
       "review_count          8529.0  \n",
       "compliments_cute      1701.0  \n",
       "compliments_writer    5178.0  \n",
       "fans                  1363.0  \n",
       "compliments_note      5121.0  \n",
       "compliments_hot      10658.0  \n",
       "compliments_cool     12148.0  \n",
       "compliments_profile   5178.0  \n",
       "average_stars            5.0  \n",
       "compliments_more      3300.0  \n",
       "votes_cool           37288.0  \n",
       "compliments_list      2057.0  \n",
       "votes_funny          36462.0  \n",
       "compliments_photos   11430.0  \n",
       "compliments_funny     7195.0  \n",
       "votes_useful         42047.0  \n",
       "elite_flag               1.0  \n",
       "elite_years             11.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'[2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]'\n",
    "\n",
    "#zero fill the nulls\n",
    "ux.fillna(0, inplace=True)\n",
    "ux.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144206,)\n",
      "(144206, 18)\n"
     ]
    }
   ],
   "source": [
    "#patsy prep\n",
    "\n",
    "form_ux = []\n",
    "[form_ux.append(x) for x in ux.columns if x not in ['elite','name','user_id','yelping_since']]\n",
    "form =  ' + '.join(form_ux) + ' - 1'\n",
    "formula = 'elite_flag ~ ' + form\n",
    "\n",
    "\n",
    "#y,X = patsy.dmatrices(formula, data=ux, return_type='dataframe')\n",
    "##patsy was too slow so plan b\n",
    "\n",
    "y = ux['elite_flag']\n",
    "X = ux\n",
    "X.drop(['elite', 'name','user_id','yelping_since','elite_flag'], axis=1, inplace=True)\n",
    "print y.shape\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = reviews.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['user_id', 'review_id', 'votes_cool', 'business_id', 'votes_funny',\n",
       "       'stars', 'date', 'votes_useful', 'ten_minutes', 'fifteen_minutes',\n",
       "       'twenty_minutes', 'thirty_minutes', 'bar_food', 'beer_selection',\n",
       "       'best_ve', 'bloody_mary', 'bottle_service', 'chicken_waffles',\n",
       "       'customer_service', 'dance_floor', 'decided_try', 'definitely_come',\n",
       "       'definitely_recommend', 'didn_want', 'don_know', 'don_like',\n",
       "       'don_think', 'don_want', 'eggs_benedict', 'fast_food', 'feel_like',\n",
       "       'felt_like', 'fish_chips', 'food_amazing', 'food_came',\n",
       "       'food_delicious', 'food_good', 'food_great', 'food_just',\n",
       "       'food_service', 'french_fries', 'french_toast', 'friday_night',\n",
       "       'fried_chicken', 'friendly_staff', 'good_food', 'good_place',\n",
       "       'good_service', 'good_thing', 'good_time', 'great_atmosphere',\n",
       "       'great_experience', 'great_food', 'great_place', 'great_service',\n",
       "       'great_time', 'happy_hour', 'hash_browns', 'highly_recommend',\n",
       "       'hip_hop', 'ice_cream', 'just_like', 'just_ok', 'just_right',\n",
       "       'las_vegas', 'late_night', 'like_place', 'little_bit', 'long_time',\n",
       "       'looked_like', 'looks_like', 'love_place', 'mac_cheese',\n",
       "       'make_sure', 'mashed_potatoes', 'medium_rare', 'minutes_later',\n",
       "       'new_york', 'onion_rings', 'place_good', 'place_great',\n",
       "       'place_just', 'potato_fries', 'pretty_good', 'quality_food',\n",
       "       'really_enjoyed', 'really_good', 'really_like', 'really_nice',\n",
       "       'recommend_place', 'red_velvet', 'right_away', 'saturday_night',\n",
       "       'second_time', 'service_excellent', 'service_food',\n",
       "       'service_friendly', 'service_good', 'service_great',\n",
       "       'staff_friendly', 'super_friendly', 'sweet_potato', 'tasted_like',\n",
       "       'time_vegas', 'try_place', 've_seen', 've_tried', 'wait_staff',\n",
       "       'uber_food', 'uber_service'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OK tried to run the below and ran into some performance issues.  So I\"m going to use the test /train split\n",
    "#to get a small sample.\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,t)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=.75,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:   23.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:  1.9min\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 24, 'weights': 'distance'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n",
      "           weights='distance')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's do Knn with gridsearch and see if we can identify a good model.\n",
    "# Set up the grid parameters\n",
    "\n",
    "params = {\n",
    "    'n_neighbors':range(1,25),\n",
    "    'weights':['uniform','distance']\n",
    "    }\n",
    "\n",
    "# fetch the model, assign the parameters and fit the model\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_gs = GridSearchCV(knn, params, cv=5, verbose=1)\n",
    "knn_gs.fit(Xtrain, ytrain)\n",
    "\n",
    "# print out the best model\n",
    "print knn_gs.best_params_\n",
    "best_knn = knn_gs.best_estimator_\n",
    "print best_knn\n",
    "\n",
    "# Calculate the predictions for the confusion matrix / residuals\n",
    "\n",
    "y_pred = knn_gs.predict(Xtrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report /n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     31895\n",
      "          1       1.00      1.00      1.00      4156\n",
      "\n",
      "avg / total       1.00      1.00      1.00     36051\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          31895     0  31895\n",
      "1              0  4156   4156\n",
      "All        31895  4156  36051\n"
     ]
    }
   ],
   "source": [
    "print \"Classification Report /n\"\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(ytrain, y_pred)\n",
    "print cls_rep\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "confusion = pd.crosstab(ytrain, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    8.8s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:  2.2min\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:  3.3min\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 20.408261224489795, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# OK let's do some logistic regression as an alternative  Results are too good.\n",
    "# Let's start with our X and Y \"full\" and see if we can process this data.  X will be normalized\n",
    "# for regularization\n",
    "\n",
    "\n",
    "X_small, X_ignore, y_small, y_ignore = train_test_split(X, y, test_size=.70,stratify = y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "#Regularize means standardize\n",
    "\n",
    "Xn = ss.fit_transform(X_small)\n",
    "\n",
    "#Xn and y small is our data (reduced to help with processing speed)\n",
    "\n",
    "lr_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.linspace(0.0001, 1000, 50)\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(LogisticRegression(), lr_params, cv=5, verbose=1)\n",
    "lr_gs.fit(Xn, y_small)\n",
    "print lr_gs.best_params_\n",
    "best_lr = lr_gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "[0.85473246272968917, 0.8741476944412343, 0.8637309292649098, 0.86985668053629217, 0.8725002889839325]\n",
      "0.866993611191\n",
      "Baseline accuracy: 0.115272596147\n"
     ]
    }
   ],
   "source": [
    "#Move forward with the best model from the grid search\n",
    "\n",
    "cv_indices = StratifiedKFold(y_small, n_folds=5)\n",
    "\n",
    "lr_scores = []\n",
    "\n",
    "for train_inds, test_inds in cv_indices:\n",
    "    \n",
    "    Xtr, ytr = Xn[train_inds, :], y[train_inds]\n",
    "    Xte, yte = Xn[test_inds, :], y[test_inds]\n",
    "    \n",
    "    best_lr.fit(Xtr, ytr)\n",
    "    lr_scores.append(best_lr.score(Xte, yte))\n",
    "\n",
    "\n",
    "print 'Logistic Regression:'\n",
    "print lr_scores\n",
    "print np.mean(lr_scores)\n",
    "\n",
    "print 'Baseline accuracy:', np.mean(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36051,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report /n\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     31895\n",
      "          1       1.00      1.00      1.00      4156\n",
      "\n",
      "avg / total       1.00      1.00      1.00     36051\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31895</td>\n",
       "      <td>0</td>\n",
       "      <td>31895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4156</td>\n",
       "      <td>4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>31895</td>\n",
       "      <td>4156</td>\n",
       "      <td>36051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0     1    All\n",
       "True                         \n",
       "0          31895     0  31895\n",
       "1              0  4156   4156\n",
       "All        31895  4156  36051"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Classification Report /n\"\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(ytrain, y_pred)\n",
    "print cls_rep\n",
    "\n",
    "\n",
    "# confusion matrix.  Note there are a couple  of methods.  Cross tab seems more flexible, readable\n",
    "pd.crosstab(ytrain, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    abs_coef      coef             variable\n",
      "11  0.231719  0.231719           votes_cool\n",
      "16  0.194693 -0.194693         votes_useful\n",
      "14  0.120289 -0.120289   compliments_photos\n",
      "5   0.101162  0.101162     compliments_note\n",
      "8   0.092708  0.092708  compliments_profile\n",
      "12  0.071595 -0.071595     compliments_list\n",
      "13  0.065177 -0.065177          votes_funny\n",
      "3   0.050000 -0.050000   compliments_writer\n",
      "1   0.043365  0.043365         review_count\n",
      "7   0.038341 -0.038341     compliments_cool\n",
      "10  0.032436 -0.032436     compliments_more\n",
      "6   0.025411 -0.025411      compliments_hot\n",
      "15  0.017244 -0.017244    compliments_funny\n",
      "2   0.016552  0.016552     compliments_cute\n",
      "4   0.010049 -0.010049                 fans\n",
      "17  0.008527  0.008527          elite_years\n",
      "0   0.007979 -0.007979    compliments_plain\n",
      "9   0.001830  0.001830        average_stars\n"
     ]
    }
   ],
   "source": [
    "z = pd.DataFrame(Xn)\n",
    "ls = X.columns.values.tolist()\n",
    "coefs = pd.DataFrame({'variable':ls,'coef':best_lr.coef_[0], 'abs_coef':np.abs(best_lr.coef_[0])})\n",
    "coefs.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "print coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's generate a new design Matrix\n",
    "X_new = X[['elite_years','fans','average_stars','review_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    8.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:   30.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 20.408261224489795, 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "#ignoring compliments and votes let's redo the logistic regression\n",
    "# Let's start with our X and Y \"full\" and see if we can process this data.  X will be normalized\n",
    "# for regularization\n",
    "\n",
    "\n",
    "X_small, X_ignore, y_small, y_ignore = train_test_split(X_new, y, test_size=.30,stratify = y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "Xn = ss.fit_transform(X_small)\n",
    "\n",
    "#Xn and y small is our data (reduced to help with processing speed)\n",
    "\n",
    "lr_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.linspace(0.0001, 1000, 50)\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(LogisticRegression(), lr_params, cv=5, verbose=1)\n",
    "lr_gs.fit(Xn, y_small)\n",
    "print lr_gs.best_params_\n",
    "best_lr = lr_gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "[0.86389301634472515, 0.86928525434642623, 0.88340185249393233, 0.88161283931048151, 0.8947394491777293]\n",
      "0.878586482335\n",
      "Baseline accuracy: 0.115272596147\n"
     ]
    }
   ],
   "source": [
    "cv_indices = StratifiedKFold(y_small, n_folds=5)\n",
    "\n",
    "lr_scores = []\n",
    "\n",
    "for train_inds, test_inds in cv_indices:\n",
    "    \n",
    "    Xtr, ytr = Xn[train_inds, :], y[train_inds]\n",
    "    Xte, yte = Xn[test_inds, :], y[test_inds]\n",
    "    \n",
    "    best_lr.fit(Xtr, ytr)\n",
    "    lr_scores.append(best_lr.score(Xte, yte))\n",
    "\n",
    "\n",
    "print 'Logistic Regression:'\n",
    "print lr_scores\n",
    "print np.mean(lr_scores)\n",
    "\n",
    "print 'Baseline accuracy:', np.mean(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94     89308\n",
      "          1       0.00      0.00      0.00     11636\n",
      "\n",
      "avg / total       0.78      0.88      0.83    100944\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted       0     All\n",
      "Actual                   \n",
      "0           89308   89308\n",
      "1           11636   11636\n",
      "All        100944  100944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/dsi/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_lr.predict(Xn)\n",
    "print type(y_pred)\n",
    "\n",
    "print \"Classification Report\"\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_small, y_pred)\n",
    "print cls_rep\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "confusion = pd.crosstab(y_small, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abs_coef      coef       variable\n",
      "0  0.017549  0.017549    elite_years\n",
      "3  0.008161 -0.008161   review_count\n",
      "1  0.006184  0.006184           fans\n",
      "2  0.004196  0.004196  average_stars\n"
     ]
    }
   ],
   "source": [
    "#more reasonable, less overfit\n",
    "ls = X_new.columns.values.tolist()\n",
    "coefs = pd.DataFrame({'variable':ls,'coef':best_lr.coef_[0], 'abs_coef':np.abs(best_lr.coef_[0])})\n",
    "coefs.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "print coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "newX = X[[ls]]\n",
    "corrs = newX.corr()\n",
    "\n",
    "# Set the default matplotlib figure size:\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Generate a mask for the upper triangle (taken from seaborn example gallery)\n",
    "mask = np.zeros_like(corrs, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Plot the heatmap with seaborn.\n",
    "# Assign the matplotlib axis the function returns. This will let us resize the labels.\n",
    "ax = sns.heatmap(corrs, mask=mask)\n",
    "\n",
    "# Resize the labels.\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14, rotation=30)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14, rotation=0)\n",
    "\n",
    "# If you put plt.show() at the bottom, it prevents those useless printouts from matplotlib.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 4. Find something interesting on your own\n",
    "\n",
    "---\n",
    "\n",
    "You want to impress your superiors at Yelp by doing some investigation into the data on your own. You want to do classification, but you're not sure on what.\n",
    "\n",
    "1. Create a hypothesis or hypotheses about the data based on whatever you are interested in, as long as it is predicting a category of some kind (classification).\n",
    "2. Explore the data visually (ideally related to this hypothesis).\n",
    "3. Build one or more classification models to predict your target variable. **Your modeling should include gridsearching to find optimal model parameters.**\n",
    "4. Evaluate the performance of your model. Explain why your model may have chosen those specific parameters during the gridsearch process.\n",
    "5. Write up what the model tells you. Does it validate or invalidate your hypothesis? Write this up as if for a non-technical audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 5. ROC and Precision-recall\n",
    "\n",
    "---\n",
    "\n",
    "Some categories have fewer overall businesses than others. Choose two categories of businesses to predict, one that makes your proportion of target classes as even as possible, and another that has very few businesses and thus makes the target varible imbalanced.\n",
    "\n",
    "1. Create two classification models predicting these categories. Optimize the models and choose variables as you see fit.\n",
    "- Make confusion matrices for your models. Describe the confusion matrices and explain what they tell you about your models' performance.\n",
    "- Make ROC curves for both models. What do the ROC curves describe and what do they tell you about your model?\n",
    "- Make Precision-Recall curves for the models. What do they describe? How do they compare to the ROC curves?\n",
    "- Explain when Precision-Recall may be preferable to ROC. Is that the case in either of your models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
